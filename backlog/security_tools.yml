security_tools:
- id: FORENSICS-001
  title: Live Memory Forensic Toolkit
  category: forensics
  description: A toolkit for acquiring and analyzing volatile memory from live systems
    to uncover evidence of advanced threats, malware, and system compromise.
  security_requirements:
  - Acquire memory images from Windows, Linux, and macOS systems with minimal footprint.
  - Analyze memory for running processes, network connections, loaded drivers, and
    code injection.
  - Carve files, registry hives, and other artifacts directly from memory dumps.
  - Detect stealthy malware techniques like rootkits and process hollowing.
  - Generate comprehensive reports in multiple formats (JSON, HTML, PDF).
  acceptance_tests:
  - Successfully acquire a memory image from a test VM.
  - Identify a hidden process in a sample memory dump.
  - Extract a malicious script from a memory image.
  - Generate a detailed report of all findings.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/forensics/memory_toolkit.py
  - tests/test_forensics_001.py
  max_changed_lines: 800
- id: MOBILE-001
  title: Mobile App Security Analyzer
  category: mobile
  description: An automated security analyzer for Android and iOS applications that
    performs static and dynamic analysis to identify vulnerabilities.
  security_requirements:
  - Decompile and analyze application binaries (APK, IPA).
  - Identify insecure data storage, weak cryptography, and improper authentication.
  - Perform dynamic analysis in an emulated environment to detect runtime vulnerabilities.
  - Scan for known vulnerabilities in third-party libraries.
  - Provide detailed vulnerability reports with remediation advice.
  acceptance_tests:
  - Analyze a sample vulnerable Android application and identify at least three critical
    vulnerabilities.
  - Detect hardcoded API keys in a test iOS application.
  - Identify insecure network communication during dynamic analysis.
  - Generate a SARIF report of the findings.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/mobile/app_analyzer.py
  - tests/test_mobile_001.py
  max_changed_lines: 900
- id: IOT-002
  title: IoT Device Firmware Analyzer
  category: iot
  description: A tool to unpack, analyze, and identify vulnerabilities in IoT device
    firmware images.
  security_requirements:
  - Extract filesystems from various firmware formats (bin, img, etc.).
  - Identify hardcoded credentials, private keys, and other secrets.
  - Analyze binaries for known vulnerabilities and insecure functions.
  - Emulate firmware to observe runtime behavior in a sandboxed environment.
  - Generate a comprehensive report of security risks.
  acceptance_tests:
  - Successfully unpack a sample firmware image.
  - Discover a hardcoded password within the firmware filesystem.
  - Identify a vulnerable library in a firmware binary.
  - Emulate the firmware and detect a backdoor service.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/iot/firmware_analyzer.py
  - tests/test_iot_002.py
  max_changed_lines: 750
- id: RECON-001
  title: Advanced Port Scanner
  category: reconnaissance
  description: Multi-threaded port scanner with service detection, banner grabbing,
    and vulnerability hints
  security_requirements:
  - TCP and UDP port scanning capabilities
  - Service version detection and banner grabbing
  - Rate limiting to avoid detection
  - Output in multiple formats (JSON, XML, CSV)
  - Stealth scanning techniques
  acceptance_tests:
  - Scan common ports (1-1000) on localhost successfully
  - Detect SSH service on port 22 with banner
  - Export results to JSON format
  - Handle rate limiting parameters
  ready: true
  status: ready_for_review
  area_allowlist:
  - tools/recon/port_scanner.py
  - tools/recon/__init__.py
  - tests/test_recon_001.py
  max_changed_lines: 800
- id: RECON-002
  title: Subdomain Hunter
  category: reconnaissance
  description: Intelligent subdomain enumeration using multiple techniques (DNS, certificates,
    search engines)
  security_requirements:
  - DNS brute force with common wordlists
  - Certificate transparency log searching
  - Search engine dorking for subdomains
  - Wildcard detection and filtering
  - Concurrent processing for speed
  acceptance_tests:
  - Find at least 5 subdomains for a test domain
  - Detect wildcard DNS configurations
  - Output unique, valid subdomains only
  - Handle timeouts gracefully
  ready: true
  status: needs_work
  area_allowlist:
  - tools/recon/subdomain_hunter.py
  - tools/recon/wordlists/
  - tests/test_recon_002.py
  max_changed_lines: 800
- id: VULN-001
  title: Hash Cracker Suite
  category: vulnerability
  description: Multi-algorithm hash cracking tool with wordlist and brute force attacks
  security_requirements:
  - Support MD5, SHA1, SHA256, SHA512, bcrypt
  - Wordlist-based attacks with custom lists
  - Brute force with character sets
  - Hash format detection
  - Progress tracking and resume capability
  acceptance_tests:
  - Crack MD5 hash of 'password' using rockyou wordlist sample
  - Detect hash algorithm automatically
  - Show progress during cracking attempts
  - Handle invalid hash formats gracefully
  ready: true
  status: needs_work
  area_allowlist:
  - tools/vuln/hash_cracker.py
  - tools/vuln/wordlists/
  - tests/test_vuln_001.py
  max_changed_lines: 900
- id: VULN-002
  title: SSL/TLS Certificate Inspector
  category: vulnerability
  description: Comprehensive SSL/TLS certificate security analysis and vulnerability
    detection
  security_requirements:
  - Certificate chain validation
  - Weak cipher suite detection
  - Certificate expiration warnings
  - Common SSL vulnerabilities (Heartbleed, POODLE, etc.)
  - Certificate transparency log verification
  acceptance_tests:
  - Analyze certificate for https://www.google.com
  - Detect certificate expiration date
  - Identify cipher suites in use
  - Flag weak encryption algorithms
  ready: true
  status: needs_work
  area_allowlist:
  - tools/vuln/cert_inspector.py
  - tests/test_vuln_002.py
  max_changed_lines: 750
- id: HUNT-001
  title: Security Log Analyzer
  category: threat_hunting
  description: Advanced log analysis tool for detecting security events and anomalies
  security_requirements:
  - Parse multiple log formats (syslog, JSON, CSV)
  - Pattern matching for known attack signatures
  - Anomaly detection using statistical analysis
  - IOC (Indicators of Compromise) correlation
  - Timeline analysis and event correlation
  acceptance_tests:
  - Parse sample Apache access logs successfully
  - Detect SQL injection attempts in logs
  - Identify suspicious IP addresses
  - Generate security event timeline
  ready: true
  status: needs_work
  area_allowlist:
  - tools/threat_hunt/log_analyzer.py
  - tools/threat_hunt/signatures/
  - tests/test_hunt_001.py
  max_changed_lines: 1000
- id: NET-001
  title: Network Traffic Analyzer
  category: network
  description: Real-time network packet analysis with security-focused detection capabilities
  security_requirements:
  - Live packet capture using pcap
  - Protocol analysis (HTTP, DNS, TCP, UDP)
  - Malicious payload detection
  - Network flow analysis
  - Export PCAP files for further analysis
  acceptance_tests:
  - Capture packets from network interface
  - Detect HTTP requests in traffic
  - Identify potential malicious domains
  - Export captured data to PCAP format
  ready: false
  status: todo
  area_allowlist:
  - tools/network/traffic_analyzer.py
  - tests/test_net_001.py
  max_changed_lines: 850
- id: CRYPTO-001
  title: Encryption Utility Suite
  category: cryptography
  description: Comprehensive encryption/decryption tool with multiple cipher support
  security_requirements:
  - AES encryption/decryption with multiple modes
  - RSA key generation and operations
  - Secure random key generation
  - File encryption with integrity verification
  - Password-based key derivation (PBKDF2)
  acceptance_tests:
  - Encrypt and decrypt a test file successfully
  - Generate secure RSA key pairs
  - Verify file integrity after encryption/decryption
  - Handle password-based encryption
  ready: true
  status: needs_work
  area_allowlist:
  - tools/crypto/encryption_suite.py
  - tests/test_crypto_001.py
  max_changed_lines: 800
- id: AISEC-001
  title: AI Model Supply Chain Auditor
  category: ai_security
  description: 'End-to-end auditing of AI pipelines: model/dataset integrity, dependency
    SBOM signing, Trojan/backdoor heuristics, and prompt-injection policy testing.'
  security_requirements:
  - Operate on offline copies of artifacts; never upload model weights or datasets.
  - Execute any untrusted code in a hardened sandbox without network egress.
  - Only read repository metadata and artifacts; no changes are made to sources or
    registries.
  acceptance_tests:
  - Given a model repository with an unsigned or mismatched signature for model weights,
    the tool flags integrity failure and halts the pipeline with a high-severity alert.
  - Given a dataset with embedded trigger patterns and an associated model, the Trojan
    scan returns an anomaly score above a configurable threshold and emits a high-confidence
    finding.
  - When running prompt-injection tests against a protected inference endpoint with
    defined allow/deny policies, injected content is detected and blocked, and audit
    logs contain the policy action and rationale.
  ready: true
  status: completed
  area_allowlist:
  - tools/ai_security/ai_model_supply_chain_auditor.py
  - tests/test_ai_security_aisec_001.py
  max_changed_lines: 800
- id: CLOUD-001
  title: Cloud IAM Drift Hunter & Attack Path Mapper
  category: cloud
  description: Builds a cross-cloud graph of identities, policies, and resources to
    detect drift and map potential privilege-escalation and lateral-movement paths
    across AWS/Azure/GCP.
  security_requirements:
  - Use cloud-native read-only permissions; never write, modify, or delete resources.
  - Scope collection to specified accounts/subscriptions/projects and respect service
    rate limits.
  - Do not retrieve or display secret values; only metadata and policy documents.
  acceptance_tests:
  - On a test tenant with a misconfigured role trust policy, the tool identifies an
    attack path from a low-privilege role to admin and provides prioritized remediation
    steps.
  - After establishing a baseline snapshot, a new inline policy is added; the subsequent
    scan reports drift with a clear diff of added permissions and affected identities.
  - When API credentials lack required read permissions, the tool fails gracefully,
    listing missing permissions and suggesting least-privilege remediation.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/iam_attack_path_mapper.py
  - tests/test_cloud_cloud_001.py
  max_changed_lines: 800
- id: IOT-001
  title: Firmware Behavior Sandbox & SBOM Analyzer
  category: iot
  description: 'Automated static and dynamic analysis of IoT firmware: SBOM extraction,
    CVE correlation, service hardening checks, secrets discovery, and emulated runtime
    network behavior.'
  security_requirements:
  - Run firmware in an isolated VM/emulator with no outbound internet by default.
  - Sanitize and anonymize any telemetry; do not retain proprietary code beyond the
    analysis session.
  - Validate firmware provenance and require explicit authorization for analysis.
  acceptance_tests:
  - Given a firmware image that starts Telnet with default credentials, the sandbox
    flags weak service configuration and reports credential exposure risk with hardening
    recommendations.
  - From an extracted SBOM containing a vulnerable OpenSSL version, the tool correlates
    relevant CVEs and outputs severity, affected components, and fixed versions.
  - If the firmware attempts DNS tunneling during emulation, the network monitor detects
    and blocks the exfiltration attempt, recording an alert with PCAP evidence references.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/iot/firmware_behavior_sandbox.py
  - tests/test_iot_iot_001.py
  max_changed_lines: 800
- id: AI-001
  title: Adversarial Canary
  category: ai_security
  description: Automated adversarial attack and poisoning simulator for ML models
    that orchestrates white-box/black-box attacks (FGSM, PGD, CW, AutoAttack), synthetic
    backdoors, data drift detection, and AI red teaming with signed, reproducible
    provenance and safety-guarded agent tooling.
  security_requirements:
  - Execute all attack/red-team workloads inside locked-down, ephemeral sandboxes
    (seccomp/AppArmor, no-new-privileges, read-only rootfs, egress denied by default
    with explicit allowlists) and emit in-toto/SLSA-3 style signed attestations binding
    model/dataset hashes, parameters, and seeds.
  - Apply content and tool-use isolation for red-team agents (strict prompt/tool policies,
    output filtering, capability-scoped APIs) with cryptographic sealing (SHA-256
    manifests + transparency log) and reproducibility guarantees (identical artifact
    digests given fixed seeds).
  acceptance_tests:
  - Given a PyTorch ResNet trained on CIFAR-10 and a 1k-sample eval set, the tool
    generates targeted and untargeted adversarial examples via FGSM and PGD, reports
    attack success rates and accuracy deltas, produces a signed provenance attestation
    containing model/dataset digests and attack parameters, blocks all container egress
    during execution, and exports a report with confusion-matrix deltas; re-verification
    of the attestation signature must succeed.
  - When injecting a 1% label-flip backdoor with a specified trigger, the tool detects
    distributional anomalies, raises a poisoning risk score >= 0.8, proposes mitigation
    (data filter + fine-tune), and on rerun with the same seed reproduces byte-identical
    adversarial samples and identical manifest hashes for all exported artifacts.
  ready: true
  status: completed
  area_allowlist:
  - tools/ai_security/adversarial_canary.py
  - tests/test_ai_001.py
  max_changed_lines: 1000
- id: SC-002
  title: SBOM Sentinel
  category: supply_chain
  description: Continuous dependency analysis and SBOM generation (SPDX/CycloneDX)
    with integrity verification, hermetic build replays, provenance attestations,
    typosquat detection, and signed transparency-backed publishing for multi-language
    projects.
  security_requirements:
  - Generate SBOMs and provenance signed with Sigstore/cosign, store and verify inclusion
    in Rekor transparency logs, and enforce fail-closed validation of signature chains
    (OIDC identities, cert chains, time-stamping).
  - Perform hermetic builds inside ephemeral, network-locked sandboxes using content-addressed
    caches and strict source allowlists; produce SLSA-3 attestations referencing exact
    inputs, toolchains, and environmental digests; block on ambiguity or non-reproducible
    outputs.
  acceptance_tests:
  - For a Python repository with transitive dependencies containing a look-alike package
    (typosquat), the tool halts the pipeline, flags the suspicious package with evidence,
    emits a CycloneDX SBOM including VEX notes for known false positives, signs the
    SBOM/provenance with cosign, and verifies Rekor inclusion and identity claims
    successfully.
  - Given two releases (v1.0.0 and v1.1.0), the tool produces a deterministic SBOM
    diff highlighting an added native binary lacking source and signature; integrity
    checks fail closed, the build is blocked, and rerunning the full pipeline yields
    identical SBOM and attestation digests.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/supply_chain/sbom_sentinel.py
  - tests/test_sc_002.py
  max_changed_lines: 1000
- id: IOT-003
  title: FuzzFox IoT
  category: iot_security
  description: Passive IoT device discovery with firmware analysis and protocol-aware
    fuzzing for MQTT, CoAP, BLE, and Modbus/TCP using stateful models, rate-limited
    traffic shaping, and microsegmented sandboxes to prevent collateral impact on
    operational networks.
  security_requirements:
  - Enforce protocol-specific rate limits and microsegmentation via eBPF network policies
    and dedicated namespaces; implement a kill-switch and health checks to quarantine
    fuzzers on anomaly, ensuring isolation of test traffic from production networks.
  - Handle firmware images in read-only, non-root containers with dropped capabilities;
    apply signed YARA rule packs for secret/artifact detection and scrub PII from
    reports while preserving forensic hashes for auditability.
  acceptance_tests:
  - On a lab segment hosting an MQTT camera and a CoAP sensor, the tool passively
    fingerprints both via mDNS/SSDP and traffic heuristics, then runs protocol-aware
    fuzzers capped at 100 packets/sec per target; no device crashes occur, at least
    one input validation issue is identified, and all fuzz traffic is contained within
    the eBPF namespace as verified by counters (no leakage to other interfaces).
  - Given a vendor firmware archive, the tool extracts the filesystem without mounting,
    detects secrets via signed YARA packs, redacts them in human-readable reports
    while preserving SHA-256 evidence in a sealed manifest, and denies any write attempts
    to the firmware path (read-only enforcement observed in logs).
  ready: true
  status: needs_work
  area_allowlist:
  - tools/iot_security/fuzzfox.py
  - tests/test_iot_003.py
  max_changed_lines: 1000
- id: CL-002
  title: 'NebulaGuard: Serverless & Container Runtime Policy Scanner'
  category: cloud_security
  description: A unified cloud-native security scanner that evaluates serverless functions
    and containerized workloads across multi-cloud environments. Combines image/IaC
    scanning, OPA policy evaluation, eBPF-based runtime detection, and signature/SBOM
    verification (cosign/Sigstore) to prevent risky deployments and to detect runtime
    escapes and secret exfiltration.
  security_requirements:
  - Cloud access uses read-only, least-privilege roles; policy enforces a denylist
    of mutation APIs and validates that no write operations are executed.
  - OPA policy bundles and rules are signed and verified before evaluation; policy
    decisions and inputs are logged with integrity hashes.
  - Container and function images must pass cosign signature verification and SBOM
    presence checks; vulnerability scanning uses vetted, periodically mirrored CVE
    feeds to support air-gapped mode.
  - Runtime sensors leverage eBPF with minimal privileges and strict filtering to
    avoid collecting sensitive environment data; data egress is rate-limited and encrypted
    in transit.
  - Multi-cloud API calls implement adaptive rate limiting and exponential backoff
    to prevent throttling and service disruption.
  - All findings are exportable in SARIF and JSON with deterministic IDs; reports
    are optionally sealed with RFC 3161 timestamps.
  acceptance_tests:
  - Given a container image with a critical CVE and no cosign signature, the tool
    fails the scan, cites CVE identifiers, refuses deployment with non-zero exit code,
    and produces both SARIF and JSON reports.
  - When scanning a Lambda function with wildcard IAM permissions and no timeout guard,
    policies flag high severity findings with least-privilege remediation guidance;
    execution trace confirms no write API calls occurred.
  - In a Kubernetes cluster, the runtime sensor detects a process escape attempt (e.g.,
    nsenter) and raises a high-confidence alert within 5 seconds without collecting
    sensitive environment variables.
  ready: true
  status: ready_for_review
  area_allowlist:
  - tools/cloud_security/nebula_guard.py
  - tests/test_cloud_002.py
  max_changed_lines: 1000
- id: SC-003
  title: 'Hermes-SBOM Sentinel: Provenance & Integrity Watcher'
  category: supply_chain
  description: A supply chain assurance platform that generates and monitors SBOMs
    (SPDX/CycloneDX), verifies artifact provenance with in-toto/SLSA attestations,
    and validates signatures/log inclusion via Sigstore (Fulcio/Rekor). It continuously
    diffs SBOMs across builds, detects typosquatting and dependency confusion, and
    enforces quarantine on integrity failures.
  security_requirements:
  - Artifact and provenance verification requires valid cosign signatures and Rekor
    inclusion proofs; failures trigger quarantine with immutable incident records.
  - In-toto attestations must satisfy SLSA Level 3 requirements; policy rejects artifacts
    lacking a complete builder and materials chain.
  - SBOMs are stored in content-addressed, append-only storage with transparency indexing;
    diffs are signed and timestamped (RFC 3161).
  - Typosquatting and dependency confusion detection uses lexical similarity, publisher
    reputation, and registry trust policies; untrusted sources are blocked by default.
  - Offline/air-gapped mode supported with pre-synced trust roots and CVE data; online
    mode uses mTLS and key pinning for upstream trust services.
  - All cryptographic primitives are selected for modern strength (Ed25519/ECDSA P-256,
    SHA-256/SHA3-256) with secure key management and rotation.
  acceptance_tests:
  - Given an artifact with an invalid cosign signature or missing Rekor entry, verification
    fails and the artifact is quarantined; the incident record includes Rekor log
    index and chain hash.
  - When presented with two consecutive builds, the SBOM diff highlights added/removed
    dependencies and flags any downgrade of critical libraries; a signed diff attestation
    is produced.
  - A package named similarly to a popular dependency but from an untrusted registry
    is flagged as potential typosquat with >95% confidence using lexical and publisher
    heuristics.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/supply_chain/hermes_sentinel.py
  - tests/test_supply_chain_003.py
  max_changed_lines: 1000
- id: CLD-001
  title: LambdaShield
  category: cloud_security
  description: Agentless multi-cloud serverless and container runtime protection with
    policy-as-code verification, runtime anomaly detection, and automated least-privilege
    remediation across AWS, Azure, and GCP.
  security_requirements:
  - Discover and inventory AWS Lambda, Azure Functions, GCP Cloud Functions, and container
    workloads with CSPM baselines and drift detection.
  - Behavioral allowlisting and anomaly detection for runtime (syscalls, DNS, network
    egress); serverless extensions capture outbound calls; block unauthorized egress
    in real time.
  - Policy-as-code (OPA/Rego) with signed policies and mandatory signature verification;
    tamper-proof change approvals and audit trail.
  - Automated least-privilege IAM and permission constraint recommendations with safe
    auto-remediation and rollback.
  - SBOM-driven layer and image scanning with critical CVE detection, embedded secret
    discovery, and CI/CD gate enforcement.
  - Cross-account and cross-cloud trust graphing to detect risky role assumptions,
    external principal abuse, and attack paths.
  acceptance_tests:
  - Deploy a serverless function attempting data exfiltration to an unauthorized domain;
    system blocks the egress and emits a high-severity finding with full call graph
    within 30 seconds.
  - Introduce an IAM trust misconfiguration enabling external account assumeRole;
    tool detects the risky path, proposes least-privilege fix, and successfully simulates
    one-click remediation with rollback capability.
  - Build and push a container image containing a critical CVE and an exposed secret;
    SBOM scanner flags both, fails the CI gate, and blocks deployment via signed policy
    enforcement.
  - Submit a tampered OPA policy to the pipeline; signature verification fails and
    the pipeline halts with an immutable audit record and provenance details.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud_security/lambdashield.py
  - tests/test_cld_001.py
  max_changed_lines: 1000
- id: SC-001
  title: SigChain Guardian
  category: supply_chain
  description: End-to-end software supply chain integrity platform that generates
    provenance-attested SBOMs, verifies signatures and attestations (Sigstore/in-toto),
    enforces SLSA policies, and detects dependency confusion and typosquatting.
  security_requirements:
  - Produce comprehensive SBOMs (CycloneDX/SPDX) for polyglot repos, including containers,
    serverless layers, and mobile packages, with provenance attestations.
  - Verify artifact signatures using keyless Sigstore (Fulcio/Rekor) and validate
    in-toto attestations; enforce SLSA L3+ policy gates.
  - Detect typosquatting and dependency confusion across private/public registries
    via DNS, namespace, and maintainer heuristic analysis.
  - Perform reproducible build verification with hermetic builds and bit-for-bit artifact
    comparison; flag non-determinism with root-cause hints.
  - Continuously diff dependencies and compute risk scores based on exploit maturity,
    maintainer reputation, and change blast radius; trigger approvals when thresholds
    are exceeded.
  - Persist transparency log mirrors and provide tamper-evident Merkle inclusion proofs
    with periodic audit reconciliation.
  acceptance_tests:
  - Publish a malicious transitive package to a private registry that shadows a public
    name; resolution attempt is blocked as dependency confusion, with a high-risk
    alert and remediation guidance.
  - Sign a build artifact with an expired certificate; verification fails, Rekor inclusion
    proof does not validate, and the release gate is blocked with actionable diagnostics.
  - Generate SBOM for a repo combining Python, Node.js, container images, and a serverless
    layer; tool achieves 100% coverage with accurate component provenance and passes
    SLSA L3 policy checks.
  - Rebuild an artifact in a hermetic environment and detect non-deterministic timestamps;
    system flags the issue and provides diff-based root-cause hints.
  - Attempt to remove entries from the transparency log mirror; tamper-evident verification
    fails and an alert is raised containing Merkle proof inconsistencies.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/supply_chain/sigchain_guardian.py
  - tests/test_sc_001.py
  max_changed_lines: 1000
- id: AISEC-002
  title: Dataset Lineage & Poison-Drift Tracer
  category: ai_security
  description: Tracks dataset/model provenance and detects poisoning/backdoors using
    influence functions, spectral signatures, and drift analysis; issues signed attestations
    and quarantines risky artifacts.
  security_requirements:
  - Execute analysis of untrusted datasets/models in isolated, no-outbound sandboxes
    with strict filesystem confinement.
  - Cryptographically sign and verify lineage/provenance attestations (in-toto/Sigstore)
    and store append-only audit logs.
  - Support opt-in privacy-preserving feature hashing/anonymization and configurable
    PII redaction.
  acceptance_tests:
  - Given a model trained with an embedded backdoor trigger, the tool flags the poisoned
    subset and raises a high-severity alert with a minimal reproducible trigger.
  - When ingesting a dataset and attestations, the full lineage chain verifies; missing/invalid
    signatures cause validation failure with a clear error.
  - Evaluating a third-party model blocks outbound network and confines writes to
    a temporary sandbox that is destroyed after completion.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/dlp_tracer.py
  - tests/test_aisec_002.py
  max_changed_lines: 500
- id: CLOUD-002
  title: HoneyCred Cloud Tripwire
  category: cloud
  description: Deploys and rotates scoped honeytokens across AWS/Azure/GCP, monitors
    for any usage via cloud logs, auto-revokes credentials, quarantines implicated
    workloads, and emits signed, forensically sound alerts with blast-radius analysis.
  security_requirements:
  - Honeytokens must be least-privileged and explicitly blocked from write/delete
    operations on critical resources.
  - Revocation and quarantine actions are idempotent, audited, and avoid destructive
    changes to customer data.
  - Detections and actions are time-synchronized, signed, and stored in tamper-evident
    storage.
  acceptance_tests:
  - When a honeytoken invokes a cloud API, the tool detects the event within 60 seconds
    and creates a signed alert including caller, source IP, and resource context.
  - Attempted use of a honeytoken to modify or delete resources fails due to enforced
    policies and is logged.
  - Upon detection, corresponding credentials are revoked and affected instances are
    tagged/quarantined per policy.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/honeycred_tripwire.py
  - tests/test_cloud_002.py
  max_changed_lines: 500
- id: HUNT-002
  title: eBPF Syscall Graph Hunter
  category: threat_hunting
  description: Collects kernel telemetry via eBPF to build process/syscall graphs,
    detects LOTL/zero-day behaviors using temporal pattern mining and signed models,
    and provides guided response playbooks.
  security_requirements:
  - Runs with least-required kernel capabilities and disables packet injection/blocking
    by default.
  - Captured telemetry is rate-limited, optionally anonymized, and encrypted in transit
    and at rest.
  - Detection rules and ML models are versioned, signed, and verified before execution.
  acceptance_tests:
  - A suspicious process chain (e.g., Word -> PowerShell -> curl) is detected as a
    LOTL pattern and raises a medium/high-severity alert.
  - Unsigned or tampered detection models fail verification, are not loaded, and generate
    a clear audit event.
  - Under telemetry spikes, adaptive sampling engages and the system maintains operation
    without packet loss or CPU starvation beyond configured thresholds.
  ready: true
  status: in_progress
  area_allowlist:
  - tools/threat_hunting/ebpf_graph_hunter.py
  - tests/test_hunt_002.py
  max_changed_lines: 500
- id: AI_SECURITY-003
  title: Aegis-LLM Runtime Policy Gateway
  category: ai_security
  description: A runtime gateway that enforces zero-trust policies for LLM-enabled
    applications by sandboxing tool execution, preventing prompt-injection-led egress,
    validating RAG sources, and detecting covert data exfiltration via semantic and
    behavioral guards.
  security_requirements:
  - Enforce strict egress controls with domain/IP allowlists, content DLP, and metadata-only
    logging to protect sensitive data.
  - Isolate tool execution with per-request sandboxes and capability tokens; deny
    SSRF/FS access by default.
  - Continuously validate RAG/document provenance via signed attestations and checksum
    verification before model ingestion.
  acceptance_tests:
  - Inject a prompt that attempts SSRF and filesystem reads; verify the gateway blocks
    the tool call and emits a high-severity alert with minimal redacted context.
  - Serve a tampered RAG document with invalid signature; confirm ingestion is denied
    and the incident is recorded with provenance details.
  - Simulate covert exfiltration via base64 and code block leakage; verify semantic/DLP
    detectors stop the response and trigger policy-guided remediation.
  ready: true
  status: todo
  area_allowlist:
  - tools/ai_security/aegis_llm_gateway.py
  - tests/test_ai_security_003.py
  max_changed_lines: 500
- id: CLOUD-003
  title: 'FederationGuard: OIDC/WIF Trust Boundary Auditor'
  category: cloud
  description: Analyzes and continuously tests cloud workload identity federation
    (OIDC/WIF) configurations across AWS/Azure/GCP to detect token replay risks, audience/issuer
    drift, CI/CD trust misbinding, and privilege escalation paths.
  security_requirements:
  - Continuously fetch and validate OIDC issuer metadata, JWKS rotation, and audience
    scoping; alert on drift or weak trust policies.
  - Simulate signed but replayed tokens across accounts/projects to verify replay
    protections and least-privilege assumptions.
  - Map CI/CD to cloud trust chains; block high-risk bindings (wildcard audiences,
    overly broad subject claims) with policy-as-code.
  acceptance_tests:
  - Detect a wildcard audience in a WIF provider; confirm high-risk alert with remediation
    steps and failing policy check.
  - Replay a previously valid CI-issued OIDC token; verify it is rejected by target
    cloud due to nonce/exp/binding enforcement and the event is logged.
  - Introduce an issuer URL drift to a lookalike domain; ensure FederationGuard flags
    the misbinding and simulates blocked access.
  ready: true
  status: todo
  area_allowlist:
  - tools/cloud/federation_guard.py
  - tests/test_cloud_003.py
  max_changed_lines: 500
- id: FORENSICS-003
  title: Container Runtime Forensic Collector
  category: forensics
  description: Performs live, low-impact acquisition from containerized workloads,
    capturing overlay filesystems, in-memory artifacts via eBPF, container metadata,
    and network snapshots with cryptographic sealing for court-ready evidence.
  security_requirements:
  - Use read-only, namespaced mounts and cgroup-aware sampling to avoid altering target
    state; rate-limit eBPF probes.
  - Produce cryptographically signed evidence packages with chain-of-custody metadata
    and reproducible manifests.
  - Scope collection by policy to exclude secrets beyond necessity; apply on-target
    encryption with operator-provided keys.
  acceptance_tests:
  - "Acquire a running container\u2019s overlay FS and process list without restarting\
    \ it; verify hash-stable, signed evidence bundle is produced."
  - Trigger capture while a high-CPU workload runs; ensure probe rate-limiting keeps
    overhead below defined threshold and no OOM occurs.
  - Attempt to collect from a container with mounted secrets; confirm policy-based
    redaction and separate sealed index of redactions.
  ready: true
  status: todo
  area_allowlist:
  - tools/forensics/container_forensic_collector.py
  - tests/test_forensics_003.py
  max_changed_lines: 500
