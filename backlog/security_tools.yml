security_tools:
- id: FORENSICS-001
  title: Live Memory Forensic Toolkit
  category: forensics
  description: A toolkit for acquiring and analyzing volatile memory from live systems
    to uncover evidence of advanced threats, malware, and system compromise.
  security_requirements:
  - Acquire memory images from Windows, Linux, and macOS systems with minimal footprint.
  - Analyze memory for running processes, network connections, loaded drivers, and
    code injection.
  - Carve files, registry hives, and other artifacts directly from memory dumps.
  - Detect stealthy malware techniques like rootkits and process hollowing.
  - Generate comprehensive reports in multiple formats (JSON, HTML, PDF).
  acceptance_tests:
  - Successfully acquire a memory image from a test VM.
  - Identify a hidden process in a sample memory dump.
  - Extract a malicious script from a memory image.
  - Generate a detailed report of all findings.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/forensics/memory_toolkit.py
  - tests/test_forensics_001.py
  max_changed_lines: 800
- id: MOBILE-001
  title: Mobile App Security Analyzer
  category: mobile
  description: An automated security analyzer for Android and iOS applications that
    performs static and dynamic analysis to identify vulnerabilities.
  security_requirements:
  - Decompile and analyze application binaries (APK, IPA).
  - Identify insecure data storage, weak cryptography, and improper authentication.
  - Perform dynamic analysis in an emulated environment to detect runtime vulnerabilities.
  - Scan for known vulnerabilities in third-party libraries.
  - Provide detailed vulnerability reports with remediation advice.
  acceptance_tests:
  - Analyze a sample vulnerable Android application and identify at least three critical
    vulnerabilities.
  - Detect hardcoded API keys in a test iOS application.
  - Identify insecure network communication during dynamic analysis.
  - Generate a SARIF report of the findings.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/mobile/app_analyzer.py
  - tests/test_mobile_001.py
  max_changed_lines: 900
- id: IOT-002
  title: IoT Device Firmware Analyzer
  category: iot
  description: A tool to unpack, analyze, and identify vulnerabilities in IoT device
    firmware images.
  security_requirements:
  - Extract filesystems from various firmware formats (bin, img, etc.).
  - Identify hardcoded credentials, private keys, and other secrets.
  - Analyze binaries for known vulnerabilities and insecure functions.
  - Emulate firmware to observe runtime behavior in a sandboxed environment.
  - Generate a comprehensive report of security risks.
  acceptance_tests:
  - Successfully unpack a sample firmware image.
  - Discover a hardcoded password within the firmware filesystem.
  - Identify a vulnerable library in a firmware binary.
  - Emulate the firmware and detect a backdoor service.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/iot/firmware_analyzer.py
  - tests/test_iot_002.py
  max_changed_lines: 750
- id: RECON-001
  title: Advanced Port Scanner
  category: reconnaissance
  description: Multi-threaded port scanner with service detection, banner grabbing,
    and vulnerability hints
  security_requirements:
  - TCP and UDP port scanning capabilities
  - Service version detection and banner grabbing
  - Rate limiting to avoid detection
  - Output in multiple formats (JSON, XML, CSV)
  - Stealth scanning techniques
  acceptance_tests:
  - Scan common ports (1-1000) on localhost successfully
  - Detect SSH service on port 22 with banner
  - Export results to JSON format
  - Handle rate limiting parameters
  ready: true
  status: ready_for_review
  area_allowlist:
  - tools/recon/port_scanner.py
  - tools/recon/__init__.py
  - tests/test_recon_001.py
  max_changed_lines: 800
- id: RECON-002
  title: Subdomain Hunter
  category: reconnaissance
  description: Intelligent subdomain enumeration using multiple techniques (DNS, certificates,
    search engines)
  security_requirements:
  - DNS brute force with common wordlists
  - Certificate transparency log searching
  - Search engine dorking for subdomains
  - Wildcard detection and filtering
  - Concurrent processing for speed
  acceptance_tests:
  - Find at least 5 subdomains for a test domain
  - Detect wildcard DNS configurations
  - Output unique, valid subdomains only
  - Handle timeouts gracefully
  ready: true
  status: needs_work
  area_allowlist:
  - tools/recon/subdomain_hunter.py
  - tools/recon/wordlists/
  - tests/test_recon_002.py
  max_changed_lines: 800
- id: VULN-001
  title: Hash Cracker Suite
  category: vulnerability
  description: Multi-algorithm hash cracking tool with wordlist and brute force attacks
  security_requirements:
  - Support MD5, SHA1, SHA256, SHA512, bcrypt
  - Wordlist-based attacks with custom lists
  - Brute force with character sets
  - Hash format detection
  - Progress tracking and resume capability
  acceptance_tests:
  - Crack MD5 hash of 'password' using rockyou wordlist sample
  - Detect hash algorithm automatically
  - Show progress during cracking attempts
  - Handle invalid hash formats gracefully
  ready: true
  status: needs_work
  area_allowlist:
  - tools/vuln/hash_cracker.py
  - tools/vuln/wordlists/
  - tests/test_vuln_001.py
  max_changed_lines: 900
- id: VULN-002
  title: SSL/TLS Certificate Inspector
  category: vulnerability
  description: Comprehensive SSL/TLS certificate security analysis and vulnerability
    detection
  security_requirements:
  - Certificate chain validation
  - Weak cipher suite detection
  - Certificate expiration warnings
  - Common SSL vulnerabilities (Heartbleed, POODLE, etc.)
  - Certificate transparency log verification
  acceptance_tests:
  - Analyze certificate for https://www.google.com
  - Detect certificate expiration date
  - Identify cipher suites in use
  - Flag weak encryption algorithms
  ready: true
  status: needs_work
  area_allowlist:
  - tools/vuln/cert_inspector.py
  - tests/test_vuln_002.py
  max_changed_lines: 750
- id: HUNT-001
  title: Security Log Analyzer
  category: threat_hunting
  description: Advanced log analysis tool for detecting security events and anomalies
  security_requirements:
  - Parse multiple log formats (syslog, JSON, CSV)
  - Pattern matching for known attack signatures
  - Anomaly detection using statistical analysis
  - IOC (Indicators of Compromise) correlation
  - Timeline analysis and event correlation
  acceptance_tests:
  - Parse sample Apache access logs successfully
  - Detect SQL injection attempts in logs
  - Identify suspicious IP addresses
  - Generate security event timeline
  ready: true
  status: needs_work
  area_allowlist:
  - tools/threat_hunt/log_analyzer.py
  - tools/threat_hunt/signatures/
  - tests/test_hunt_001.py
  max_changed_lines: 1000
- id: NET-001
  title: Network Traffic Analyzer
  category: network
  description: Real-time network packet analysis with security-focused detection capabilities
  security_requirements:
  - Live packet capture using pcap
  - Protocol analysis (HTTP, DNS, TCP, UDP)
  - Malicious payload detection
  - Network flow analysis
  - Export PCAP files for further analysis
  acceptance_tests:
  - Capture packets from network interface
  - Detect HTTP requests in traffic
  - Identify potential malicious domains
  - Export captured data to PCAP format
  ready: false
  status: todo
  area_allowlist:
  - tools/network/traffic_analyzer.py
  - tests/test_net_001.py
  max_changed_lines: 850
- id: CRYPTO-001
  title: Encryption Utility Suite
  category: cryptography
  description: Comprehensive encryption/decryption tool with multiple cipher support
  security_requirements:
  - AES encryption/decryption with multiple modes
  - RSA key generation and operations
  - Secure random key generation
  - File encryption with integrity verification
  - Password-based key derivation (PBKDF2)
  acceptance_tests:
  - Encrypt and decrypt a test file successfully
  - Generate secure RSA key pairs
  - Verify file integrity after encryption/decryption
  - Handle password-based encryption
  ready: true
  status: needs_work
  area_allowlist:
  - tools/crypto/encryption_suite.py
  - tests/test_crypto_001.py
  max_changed_lines: 800
- id: AISEC-001
  title: AI Model Supply Chain Auditor
  category: ai_security
  description: 'End-to-end auditing of AI pipelines: model/dataset integrity, dependency
    SBOM signing, Trojan/backdoor heuristics, and prompt-injection policy testing.'
  security_requirements:
  - Operate on offline copies of artifacts; never upload model weights or datasets.
  - Execute any untrusted code in a hardened sandbox without network egress.
  - Only read repository metadata and artifacts; no changes are made to sources or
    registries.
  acceptance_tests:
  - Given a model repository with an unsigned or mismatched signature for model weights,
    the tool flags integrity failure and halts the pipeline with a high-severity alert.
  - Given a dataset with embedded trigger patterns and an associated model, the Trojan
    scan returns an anomaly score above a configurable threshold and emits a high-confidence
    finding.
  - When running prompt-injection tests against a protected inference endpoint with
    defined allow/deny policies, injected content is detected and blocked, and audit
    logs contain the policy action and rationale.
  ready: true
  status: completed
  area_allowlist:
  - tools/ai_security/ai_model_supply_chain_auditor.py
  - tests/test_ai_security_aisec_001.py
  max_changed_lines: 800
- id: CLOUD-001
  title: Cloud IAM Drift Hunter & Attack Path Mapper
  category: cloud
  description: Builds a cross-cloud graph of identities, policies, and resources to
    detect drift and map potential privilege-escalation and lateral-movement paths
    across AWS/Azure/GCP.
  security_requirements:
  - Use cloud-native read-only permissions; never write, modify, or delete resources.
  - Scope collection to specified accounts/subscriptions/projects and respect service
    rate limits.
  - Do not retrieve or display secret values; only metadata and policy documents.
  acceptance_tests:
  - On a test tenant with a misconfigured role trust policy, the tool identifies an
    attack path from a low-privilege role to admin and provides prioritized remediation
    steps.
  - After establishing a baseline snapshot, a new inline policy is added; the subsequent
    scan reports drift with a clear diff of added permissions and affected identities.
  - When API credentials lack required read permissions, the tool fails gracefully,
    listing missing permissions and suggesting least-privilege remediation.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/iam_attack_path_mapper.py
  - tests/test_cloud_cloud_001.py
  max_changed_lines: 800
- id: IOT-001
  title: Firmware Behavior Sandbox & SBOM Analyzer
  category: iot
  description: 'Automated static and dynamic analysis of IoT firmware: SBOM extraction,
    CVE correlation, service hardening checks, secrets discovery, and emulated runtime
    network behavior.'
  security_requirements:
  - Run firmware in an isolated VM/emulator with no outbound internet by default.
  - Sanitize and anonymize any telemetry; do not retain proprietary code beyond the
    analysis session.
  - Validate firmware provenance and require explicit authorization for analysis.
  acceptance_tests:
  - Given a firmware image that starts Telnet with default credentials, the sandbox
    flags weak service configuration and reports credential exposure risk with hardening
    recommendations.
  - From an extracted SBOM containing a vulnerable OpenSSL version, the tool correlates
    relevant CVEs and outputs severity, affected components, and fixed versions.
  - If the firmware attempts DNS tunneling during emulation, the network monitor detects
    and blocks the exfiltration attempt, recording an alert with PCAP evidence references.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/iot/firmware_behavior_sandbox.py
  - tests/test_iot_iot_001.py
  max_changed_lines: 800
- id: AI-001
  title: Adversarial Canary
  category: ai_security
  description: Automated adversarial attack and poisoning simulator for ML models
    that orchestrates white-box/black-box attacks (FGSM, PGD, CW, AutoAttack), synthetic
    backdoors, data drift detection, and AI red teaming with signed, reproducible
    provenance and safety-guarded agent tooling.
  security_requirements:
  - Execute all attack/red-team workloads inside locked-down, ephemeral sandboxes
    (seccomp/AppArmor, no-new-privileges, read-only rootfs, egress denied by default
    with explicit allowlists) and emit in-toto/SLSA-3 style signed attestations binding
    model/dataset hashes, parameters, and seeds.
  - Apply content and tool-use isolation for red-team agents (strict prompt/tool policies,
    output filtering, capability-scoped APIs) with cryptographic sealing (SHA-256
    manifests + transparency log) and reproducibility guarantees (identical artifact
    digests given fixed seeds).
  acceptance_tests:
  - Given a PyTorch ResNet trained on CIFAR-10 and a 1k-sample eval set, the tool
    generates targeted and untargeted adversarial examples via FGSM and PGD, reports
    attack success rates and accuracy deltas, produces a signed provenance attestation
    containing model/dataset digests and attack parameters, blocks all container egress
    during execution, and exports a report with confusion-matrix deltas; re-verification
    of the attestation signature must succeed.
  - When injecting a 1% label-flip backdoor with a specified trigger, the tool detects
    distributional anomalies, raises a poisoning risk score >= 0.8, proposes mitigation
    (data filter + fine-tune), and on rerun with the same seed reproduces byte-identical
    adversarial samples and identical manifest hashes for all exported artifacts.
  ready: true
  status: completed
  area_allowlist:
  - tools/ai_security/adversarial_canary.py
  - tests/test_ai_001.py
  max_changed_lines: 1000
- id: SC-002
  title: SBOM Sentinel
  category: supply_chain
  description: Continuous dependency analysis and SBOM generation (SPDX/CycloneDX)
    with integrity verification, hermetic build replays, provenance attestations,
    typosquat detection, and signed transparency-backed publishing for multi-language
    projects.
  security_requirements:
  - Generate SBOMs and provenance signed with Sigstore/cosign, store and verify inclusion
    in Rekor transparency logs, and enforce fail-closed validation of signature chains
    (OIDC identities, cert chains, time-stamping).
  - Perform hermetic builds inside ephemeral, network-locked sandboxes using content-addressed
    caches and strict source allowlists; produce SLSA-3 attestations referencing exact
    inputs, toolchains, and environmental digests; block on ambiguity or non-reproducible
    outputs.
  acceptance_tests:
  - For a Python repository with transitive dependencies containing a look-alike package
    (typosquat), the tool halts the pipeline, flags the suspicious package with evidence,
    emits a CycloneDX SBOM including VEX notes for known false positives, signs the
    SBOM/provenance with cosign, and verifies Rekor inclusion and identity claims
    successfully.
  - Given two releases (v1.0.0 and v1.1.0), the tool produces a deterministic SBOM
    diff highlighting an added native binary lacking source and signature; integrity
    checks fail closed, the build is blocked, and rerunning the full pipeline yields
    identical SBOM and attestation digests.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/supply_chain/sbom_sentinel.py
  - tests/test_sc_002.py
  max_changed_lines: 1000
- id: IOT-003
  title: FuzzFox IoT
  category: iot_security
  description: Passive IoT device discovery with firmware analysis and protocol-aware
    fuzzing for MQTT, CoAP, BLE, and Modbus/TCP using stateful models, rate-limited
    traffic shaping, and microsegmented sandboxes to prevent collateral impact on
    operational networks.
  security_requirements:
  - Enforce protocol-specific rate limits and microsegmentation via eBPF network policies
    and dedicated namespaces; implement a kill-switch and health checks to quarantine
    fuzzers on anomaly, ensuring isolation of test traffic from production networks.
  - Handle firmware images in read-only, non-root containers with dropped capabilities;
    apply signed YARA rule packs for secret/artifact detection and scrub PII from
    reports while preserving forensic hashes for auditability.
  acceptance_tests:
  - On a lab segment hosting an MQTT camera and a CoAP sensor, the tool passively
    fingerprints both via mDNS/SSDP and traffic heuristics, then runs protocol-aware
    fuzzers capped at 100 packets/sec per target; no device crashes occur, at least
    one input validation issue is identified, and all fuzz traffic is contained within
    the eBPF namespace as verified by counters (no leakage to other interfaces).
  - Given a vendor firmware archive, the tool extracts the filesystem without mounting,
    detects secrets via signed YARA packs, redacts them in human-readable reports
    while preserving SHA-256 evidence in a sealed manifest, and denies any write attempts
    to the firmware path (read-only enforcement observed in logs).
  ready: true
  status: needs_work
  area_allowlist:
  - tools/iot_security/fuzzfox.py
  - tests/test_iot_003.py
  max_changed_lines: 1000
- id: CL-002
  title: 'NebulaGuard: Serverless & Container Runtime Policy Scanner'
  category: cloud_security
  description: A unified cloud-native security scanner that evaluates serverless functions
    and containerized workloads across multi-cloud environments. Combines image/IaC
    scanning, OPA policy evaluation, eBPF-based runtime detection, and signature/SBOM
    verification (cosign/Sigstore) to prevent risky deployments and to detect runtime
    escapes and secret exfiltration.
  security_requirements:
  - Cloud access uses read-only, least-privilege roles; policy enforces a denylist
    of mutation APIs and validates that no write operations are executed.
  - OPA policy bundles and rules are signed and verified before evaluation; policy
    decisions and inputs are logged with integrity hashes.
  - Container and function images must pass cosign signature verification and SBOM
    presence checks; vulnerability scanning uses vetted, periodically mirrored CVE
    feeds to support air-gapped mode.
  - Runtime sensors leverage eBPF with minimal privileges and strict filtering to
    avoid collecting sensitive environment data; data egress is rate-limited and encrypted
    in transit.
  - Multi-cloud API calls implement adaptive rate limiting and exponential backoff
    to prevent throttling and service disruption.
  - All findings are exportable in SARIF and JSON with deterministic IDs; reports
    are optionally sealed with RFC 3161 timestamps.
  acceptance_tests:
  - Given a container image with a critical CVE and no cosign signature, the tool
    fails the scan, cites CVE identifiers, refuses deployment with non-zero exit code,
    and produces both SARIF and JSON reports.
  - When scanning a Lambda function with wildcard IAM permissions and no timeout guard,
    policies flag high severity findings with least-privilege remediation guidance;
    execution trace confirms no write API calls occurred.
  - In a Kubernetes cluster, the runtime sensor detects a process escape attempt (e.g.,
    nsenter) and raises a high-confidence alert within 5 seconds without collecting
    sensitive environment variables.
  ready: true
  status: ready_for_review
  area_allowlist:
  - tools/cloud_security/nebula_guard.py
  - tests/test_cloud_002.py
  max_changed_lines: 1000
- id: SC-003
  title: 'Hermes-SBOM Sentinel: Provenance & Integrity Watcher'
  category: supply_chain
  description: A supply chain assurance platform that generates and monitors SBOMs
    (SPDX/CycloneDX), verifies artifact provenance with in-toto/SLSA attestations,
    and validates signatures/log inclusion via Sigstore (Fulcio/Rekor). It continuously
    diffs SBOMs across builds, detects typosquatting and dependency confusion, and
    enforces quarantine on integrity failures.
  security_requirements:
  - Artifact and provenance verification requires valid cosign signatures and Rekor
    inclusion proofs; failures trigger quarantine with immutable incident records.
  - In-toto attestations must satisfy SLSA Level 3 requirements; policy rejects artifacts
    lacking a complete builder and materials chain.
  - SBOMs are stored in content-addressed, append-only storage with transparency indexing;
    diffs are signed and timestamped (RFC 3161).
  - Typosquatting and dependency confusion detection uses lexical similarity, publisher
    reputation, and registry trust policies; untrusted sources are blocked by default.
  - Offline/air-gapped mode supported with pre-synced trust roots and CVE data; online
    mode uses mTLS and key pinning for upstream trust services.
  - All cryptographic primitives are selected for modern strength (Ed25519/ECDSA P-256,
    SHA-256/SHA3-256) with secure key management and rotation.
  acceptance_tests:
  - Given an artifact with an invalid cosign signature or missing Rekor entry, verification
    fails and the artifact is quarantined; the incident record includes Rekor log
    index and chain hash.
  - When presented with two consecutive builds, the SBOM diff highlights added/removed
    dependencies and flags any downgrade of critical libraries; a signed diff attestation
    is produced.
  - A package named similarly to a popular dependency but from an untrusted registry
    is flagged as potential typosquat with >95% confidence using lexical and publisher
    heuristics.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/supply_chain/hermes_sentinel.py
  - tests/test_supply_chain_003.py
  max_changed_lines: 1000
- id: CLD-001
  title: LambdaShield
  category: cloud_security
  description: Agentless multi-cloud serverless and container runtime protection with
    policy-as-code verification, runtime anomaly detection, and automated least-privilege
    remediation across AWS, Azure, and GCP.
  security_requirements:
  - Discover and inventory AWS Lambda, Azure Functions, GCP Cloud Functions, and container
    workloads with CSPM baselines and drift detection.
  - Behavioral allowlisting and anomaly detection for runtime (syscalls, DNS, network
    egress); serverless extensions capture outbound calls; block unauthorized egress
    in real time.
  - Policy-as-code (OPA/Rego) with signed policies and mandatory signature verification;
    tamper-proof change approvals and audit trail.
  - Automated least-privilege IAM and permission constraint recommendations with safe
    auto-remediation and rollback.
  - SBOM-driven layer and image scanning with critical CVE detection, embedded secret
    discovery, and CI/CD gate enforcement.
  - Cross-account and cross-cloud trust graphing to detect risky role assumptions,
    external principal abuse, and attack paths.
  acceptance_tests:
  - Deploy a serverless function attempting data exfiltration to an unauthorized domain;
    system blocks the egress and emits a high-severity finding with full call graph
    within 30 seconds.
  - Introduce an IAM trust misconfiguration enabling external account assumeRole;
    tool detects the risky path, proposes least-privilege fix, and successfully simulates
    one-click remediation with rollback capability.
  - Build and push a container image containing a critical CVE and an exposed secret;
    SBOM scanner flags both, fails the CI gate, and blocks deployment via signed policy
    enforcement.
  - Submit a tampered OPA policy to the pipeline; signature verification fails and
    the pipeline halts with an immutable audit record and provenance details.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud_security/lambdashield.py
  - tests/test_cld_001.py
  max_changed_lines: 1000
- id: SC-001
  title: SigChain Guardian
  category: supply_chain
  description: End-to-end software supply chain integrity platform that generates
    provenance-attested SBOMs, verifies signatures and attestations (Sigstore/in-toto),
    enforces SLSA policies, and detects dependency confusion and typosquatting.
  security_requirements:
  - Produce comprehensive SBOMs (CycloneDX/SPDX) for polyglot repos, including containers,
    serverless layers, and mobile packages, with provenance attestations.
  - Verify artifact signatures using keyless Sigstore (Fulcio/Rekor) and validate
    in-toto attestations; enforce SLSA L3+ policy gates.
  - Detect typosquatting and dependency confusion across private/public registries
    via DNS, namespace, and maintainer heuristic analysis.
  - Perform reproducible build verification with hermetic builds and bit-for-bit artifact
    comparison; flag non-determinism with root-cause hints.
  - Continuously diff dependencies and compute risk scores based on exploit maturity,
    maintainer reputation, and change blast radius; trigger approvals when thresholds
    are exceeded.
  - Persist transparency log mirrors and provide tamper-evident Merkle inclusion proofs
    with periodic audit reconciliation.
  acceptance_tests:
  - Publish a malicious transitive package to a private registry that shadows a public
    name; resolution attempt is blocked as dependency confusion, with a high-risk
    alert and remediation guidance.
  - Sign a build artifact with an expired certificate; verification fails, Rekor inclusion
    proof does not validate, and the release gate is blocked with actionable diagnostics.
  - Generate SBOM for a repo combining Python, Node.js, container images, and a serverless
    layer; tool achieves 100% coverage with accurate component provenance and passes
    SLSA L3 policy checks.
  - Rebuild an artifact in a hermetic environment and detect non-deterministic timestamps;
    system flags the issue and provides diff-based root-cause hints.
  - Attempt to remove entries from the transparency log mirror; tamper-evident verification
    fails and an alert is raised containing Merkle proof inconsistencies.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/supply_chain/sigchain_guardian.py
  - tests/test_sc_001.py
  max_changed_lines: 1000
- id: AISEC-002
  title: Dataset Lineage & Poison-Drift Tracer
  category: ai_security
  description: Tracks dataset/model provenance and detects poisoning/backdoors using
    influence functions, spectral signatures, and drift analysis; issues signed attestations
    and quarantines risky artifacts.
  security_requirements:
  - Execute analysis of untrusted datasets/models in isolated, no-outbound sandboxes
    with strict filesystem confinement.
  - Cryptographically sign and verify lineage/provenance attestations (in-toto/Sigstore)
    and store append-only audit logs.
  - Support opt-in privacy-preserving feature hashing/anonymization and configurable
    PII redaction.
  acceptance_tests:
  - Given a model trained with an embedded backdoor trigger, the tool flags the poisoned
    subset and raises a high-severity alert with a minimal reproducible trigger.
  - When ingesting a dataset and attestations, the full lineage chain verifies; missing/invalid
    signatures cause validation failure with a clear error.
  - Evaluating a third-party model blocks outbound network and confines writes to
    a temporary sandbox that is destroyed after completion.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/dlp_tracer.py
  - tests/test_aisec_002.py
  max_changed_lines: 500
- id: CLOUD-002
  title: HoneyCred Cloud Tripwire
  category: cloud
  description: Deploys and rotates scoped honeytokens across AWS/Azure/GCP, monitors
    for any usage via cloud logs, auto-revokes credentials, quarantines implicated
    workloads, and emits signed, forensically sound alerts with blast-radius analysis.
  security_requirements:
  - Honeytokens must be least-privileged and explicitly blocked from write/delete
    operations on critical resources.
  - Revocation and quarantine actions are idempotent, audited, and avoid destructive
    changes to customer data.
  - Detections and actions are time-synchronized, signed, and stored in tamper-evident
    storage.
  acceptance_tests:
  - When a honeytoken invokes a cloud API, the tool detects the event within 60 seconds
    and creates a signed alert including caller, source IP, and resource context.
  - Attempted use of a honeytoken to modify or delete resources fails due to enforced
    policies and is logged.
  - Upon detection, corresponding credentials are revoked and affected instances are
    tagged/quarantined per policy.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/honeycred_tripwire.py
  - tests/test_cloud_002.py
  max_changed_lines: 500
- id: HUNT-002
  title: eBPF Syscall Graph Hunter
  category: threat_hunting
  description: Collects kernel telemetry via eBPF to build process/syscall graphs,
    detects LOTL/zero-day behaviors using temporal pattern mining and signed models,
    and provides guided response playbooks.
  security_requirements:
  - Runs with least-required kernel capabilities and disables packet injection/blocking
    by default.
  - Captured telemetry is rate-limited, optionally anonymized, and encrypted in transit
    and at rest.
  - Detection rules and ML models are versioned, signed, and verified before execution.
  acceptance_tests:
  - A suspicious process chain (e.g., Word -> PowerShell -> curl) is detected as a
    LOTL pattern and raises a medium/high-severity alert.
  - Unsigned or tampered detection models fail verification, are not loaded, and generate
    a clear audit event.
  - Under telemetry spikes, adaptive sampling engages and the system maintains operation
    without packet loss or CPU starvation beyond configured thresholds.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/threat_hunting/ebpf_graph_hunter.py
  - tests/test_hunt_002.py
  max_changed_lines: 500
- id: AI_SECURITY-003
  title: Aegis-LLM Runtime Policy Gateway
  category: ai_security
  description: A runtime gateway that enforces zero-trust policies for LLM-enabled
    applications by sandboxing tool execution, preventing prompt-injection-led egress,
    validating RAG sources, and detecting covert data exfiltration via semantic and
    behavioral guards.
  security_requirements:
  - Enforce strict egress controls with domain/IP allowlists, content DLP, and metadata-only
    logging to protect sensitive data.
  - Isolate tool execution with per-request sandboxes and capability tokens; deny
    SSRF/FS access by default.
  - Continuously validate RAG/document provenance via signed attestations and checksum
    verification before model ingestion.
  acceptance_tests:
  - Inject a prompt that attempts SSRF and filesystem reads; verify the gateway blocks
    the tool call and emits a high-severity alert with minimal redacted context.
  - Serve a tampered RAG document with invalid signature; confirm ingestion is denied
    and the incident is recorded with provenance details.
  - Simulate covert exfiltration via base64 and code block leakage; verify semantic/DLP
    detectors stop the response and trigger policy-guided remediation.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/aegis_llm_gateway.py
  - tests/test_ai_security_003.py
  max_changed_lines: 500
- id: CLOUD-003
  title: 'FederationGuard: OIDC/WIF Trust Boundary Auditor'
  category: cloud
  description: Analyzes and continuously tests cloud workload identity federation
    (OIDC/WIF) configurations across AWS/Azure/GCP to detect token replay risks, audience/issuer
    drift, CI/CD trust misbinding, and privilege escalation paths.
  security_requirements:
  - Continuously fetch and validate OIDC issuer metadata, JWKS rotation, and audience
    scoping; alert on drift or weak trust policies.
  - Simulate signed but replayed tokens across accounts/projects to verify replay
    protections and least-privilege assumptions.
  - Map CI/CD to cloud trust chains; block high-risk bindings (wildcard audiences,
    overly broad subject claims) with policy-as-code.
  acceptance_tests:
  - Detect a wildcard audience in a WIF provider; confirm high-risk alert with remediation
    steps and failing policy check.
  - Replay a previously valid CI-issued OIDC token; verify it is rejected by target
    cloud due to nonce/exp/binding enforcement and the event is logged.
  - Introduce an issuer URL drift to a lookalike domain; ensure FederationGuard flags
    the misbinding and simulates blocked access.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/federation_guard.py
  - tests/test_cloud_003.py
  max_changed_lines: 500
- id: FORENSICS-003
  title: Container Runtime Forensic Collector
  category: forensics
  description: Performs live, low-impact acquisition from containerized workloads,
    capturing overlay filesystems, in-memory artifacts via eBPF, container metadata,
    and network snapshots with cryptographic sealing for court-ready evidence.
  security_requirements:
  - Use read-only, namespaced mounts and cgroup-aware sampling to avoid altering target
    state; rate-limit eBPF probes.
  - Produce cryptographically signed evidence packages with chain-of-custody metadata
    and reproducible manifests.
  - Scope collection by policy to exclude secrets beyond necessity; apply on-target
    encryption with operator-provided keys.
  acceptance_tests:
  - "Acquire a running container\u2019s overlay FS and process list without restarting\
    \ it; verify hash-stable, signed evidence bundle is produced."
  - Trigger capture while a high-CPU workload runs; ensure probe rate-limiting keeps
    overhead below defined threshold and no OOM occurs.
  - Attempt to collect from a container with mounted secrets; confirm policy-based
    redaction and separate sealed index of redactions.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/forensics/container_forensic_collector.py
  - tests/test_forensics_003.py
  max_changed_lines: 500
- id: FORENSICS-004
  title: GPU VRAM Forensic Extractor & ML Artifact Hunter
  category: forensics
  description: Performs low-impact acquisition and analysis of GPU VRAM across NVIDIA/AMD/iGPU
    to recover ML model fragments, plaintext secrets, and crypto material, producing
    cryptographically sealed, court-ready reports.
  security_requirements:
  - Acquisition must be read-only, vendor-API or DMA-safe with signed kernel modules;
    all artifacts hashed (SHA-256) and sealed with timestamped attestations.
  - Analyzer runs sandboxed with no code execution in target context; parsing uses
    memory-safe languages or fuzzed parsers to prevent malicious sample exploitation.
  - Chain-of-custody enforced via Sigstore/in-toto attestations; keys stored in HSM/KMS
    and access audited.
  acceptance_tests:
  - On a host running a GPU-accelerated ML workload, capture a VRAM snapshot and identify
    float32 tensor blocks matching model weight patterns; emit a sealed report with
    offsets and confidence scores.
  - Detect and redact API keys discovered in VRAM from human-readable outputs while
    preserving an encrypted, sealed original artifact for legal review.
  - On systems without a supported GPU, gracefully emit a signed nil-attestation with
    reason codes and zero artifacts.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/forensics/gpu_vram_artifact_hunter.py
  - tests/test_forensics_004.py
  max_changed_lines: 500
- id: NET-002
  title: QUIC/TLS Encrypted Traffic Behavioral IDS
  category: network
  description: A privacy-preserving IDS that detects C2, exfiltration, and lateral
    movement within TLS 1.3 and QUIC/HTTP3 using JA4/JA4S fingerprints, QUIC spin-bit/timing
    features, ALPN/SNI metadata, and ML-based anomaly models without decrypting payloads.
  security_requirements:
  - Collect only metadata features (no payload decryption); apply hashing/anonymization
    to PII fields and enforce configurable data retention.
  - eBPF programs must be verified, sandboxed, and rate-limited; feature extraction
    must not introduce packet drops beyond a defined budget.
  - Models and rules are versioned and signed; detections include explainable feature
    vectors and confidence scores.
  acceptance_tests:
  - Generate simulated QUIC-based C2 with uncommon JA4 and abnormal spin-bit entropy;
    system raises a high-confidence alert including the contributing features and
    fingerprints.
  - Baseline known CDN traffic (e.g., video streaming) and demonstrate reduced false
    positives after an unsupervised learning warm-up phase.
  - Operate on Linux kernel >= 5.10 with eBPF enabled and export structured JSON events
    to a SIEM endpoint with backpressure handling.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/network/quic_behavior_ids.py
  - tests/test_net_002.py
  max_changed_lines: 500
- id: CLOUD-004
  title: Shadow SaaS/OIDC App Exposure Hunter
  category: cloud
  description: Discovers unmanaged OAuth/OIDC apps across IdPs (Okta/AzureAD/Google),
    validates app security posture (PKCE, redirect URIs, consent), correlates with
    cloud logs to detect token replay/misuse, and offers policy-as-code remediation
    with signed attestations.
  security_requirements:
  - Default operation is read-only discovery with explicit approval gates for remediation;
    all actions audit-logged and signed.
  - Use least-privilege scoped API tokens stored via KMS/HSM; ephemeral credentials
    preferred with automatic rotation and revocation.
  - Safe verifier for redirect URIs that tests without enabling open redirects; adheres
    to IdP and cloud provider rate limits and backoff.
  acceptance_tests:
  - Identify an OAuth app lacking PKCE and using wildcard redirect URIs; simulate
    a benign auth flow and flag misconfiguration with prioritized remediation steps.
  - Correlate cloud access logs to detect an id_token replay from an anomalous IP/UA;
    produce a blast-radius report and revocation recommendations.
  - Produce a Sigstore-signed attestation enumerating discovered apps, risk scores,
    and policy compliance results suitable for CI/CD gating.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/shadow_oidc_app_hunter.py
  - tests/test_cloud_004.py
  max_changed_lines: 500
- id: AI_SECURITY-004
  title: 'ModelExfil Guard: Model Stealing & Adversarial Query Detector'
  category: ai_security
  description: Detects model-stealing, fine-tuning abuse, and adversarial query campaigns
    by profiling query semantics/entropy, watermark challenges, and behavioral fingerprints
    across API and self-hosted LLM endpoints; enforces adaptive throttling and produces
    signed, forensically sound audit trails.
  security_requirements:
  - 'Privacy-preserving telemetry: only store hashed/aggregated features (n-gram stats,
    perplexity bins, embedding LSH), apply differential privacy noise, and redact
    PII by default.'
  - Signed, append-only audit logs and alerts using Sigstore/Rekor with tamper-evident
    digests and time-stamping for chain-of-custody.
  - 'Safety-first enforcement: challenge/ratelimit/deny policies that never alter
    model weights or prompts; explicit rollback and dry-run modes.'
  acceptance_tests:
  - Simulate a KnockoffNets-style extraction (decision/query-only) against a public
    endpoint; detector flags anomalous query distribution and raises a high-severity
    alert with client fingerprint correlation.
  - Issue rotating-IP burst queries with jailbreak tokens; system escalates to challenge
    mode (canary/watermark prompts), detects prompt-injection patterns, and throttles
    the client.
  - Generate an incident report and verify it is signed, includes only feature-level
    telemetry (no raw prompts), and is verifiable via Rekor inclusion proof.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/modelexfil_guard.py
  - tests/test_ai_security_004.py
  max_changed_lines: 500
- id: CLOUD-005
  title: 'DataPerimeter Probe: Cloud Data Egress Policy Validator'
  category: cloud
  description: Continuously validates AWS/Azure/GCP data perimeter controls (S3/GCS/Blob
    + VPC/VNet/VPC-SC/PrivateLink) using cryptographic canaries, policy-as-code checks
    (OPA), and non-destructive egress simulations to uncover bypasses via presigned
    URLs, cross-account roles, and mis-scoped endpoints.
  security_requirements:
  - Scoped, read-only discovery and write-only to dedicated test resources with labels/TTL;
    no destructive operations on production assets.
  - Rate-limited probes with explicit account/project/region allowlists; automatic
    pause on anomaly spikes or guardrail violations.
  - Canary objects and tokens are uniquely identified, signed, and time-bounded; all
    probe actions are logged with correlation IDs and immutable storage.
  acceptance_tests:
  - On a bucket missing VPC/Private Endpoint constraints, simulate an egress read
    from an untrusted network and verify the tool detects and reports the leak path
    with remediation.
  - Create a presigned URL and attempt cross-region access; confirm the event is detected,
    correlated with CloudTrail/Azure Activity Logs/GCP Audit Logs, and includes the
    correct correlation ID.
  - Verify auto-cleanup removes only labeled canary resources and that no production
    bucket policies or objects are modified.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/dataperimeter_probe.py
  - tests/test_cloud_005.py
  max_changed_lines: 500
- id: IOT-004
  title: 'CANary Lab: Automotive UDS/CAN Fuzzer & Forensic Recorder'
  category: iot
  description: Stateful, safety-aware fuzzing and diagnostics of automotive networks
    (CAN, ISO-TP, UDS) with rate-limited service probing (e.g., 0x10/0x11/0x27), automatic
    rollback to passive sniffing on critical DTCs, and signed evidence bundles (PCAP+UDS
    transcripts) for incident response.
  security_requirements:
  - 'Hardware-in-the-loop safety: enforce vehicle speed/RPM gating, VIN/ECU allowlists,
    and safe service sets; require explicit operator confirmation for riskier UDS
    services.'
  - 'Rate control and session awareness: inter-frame gaps, busload limits, and state
    tracking to avoid bricking ECUs; immediate fail-safe on airbags/ABS/powertrain
    fault codes.'
  - 'Evidence integrity: cryptographically sign captures, transcripts, and manifests
    with synchronized time sources; store hashes in an append-only log.'
  acceptance_tests:
  - Against a test bench ECU, detect an unsecured diagnostic session (default seed/key)
    and log a finding when securityAccess is granted using a known weak algorithm.
  - While actively probing, simulate vehicle speed above threshold; tool halts active
    fuzzing and switches to passive sniffing, emitting a safety event.
  - Export a signed evidence bundle containing CAN PCAP, UDS transcript, and manifest;
    verify signatures and hash chain correctness.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/iot/canary_lab.py
  - tests/test_iot_004.py
  max_changed_lines: 500
- id: AISEC-005
  title: 'TrainSentinel: Real-time Poison & Backdoor Guard for Distributed ML Training'
  category: ai_security
  description: Instruments PyTorch/TF/JAX training runs to score batches for poisoning/backdoors
    via spectral signatures, activation clustering, and gradient norm/variance drift;
    enforces DP/clipping invariants, seeds canary samples, halts or quarantines suspect
    steps, and emits signed, reproducible attestations for CI/CD gates across GPU/TPU
    clusters.
  security_requirements:
  - Operate with least privilege as a sidecar/plug-in with read-only hooks to gradients/activations;
    never persist raw training data; encrypt telemetry in transit and at rest.
  - Produce verifiable provenance (Sigstore/in-toto) for detections and model checkpoints;
    deterministic configs with policy-as-code allowlists for frameworks and nodes.
  - 'Safe-guard actions: phase to shadow mode by default, human-approval gates for
    training halts, automatic rollback to last safe checkpoint without data loss.'
  acceptance_tests:
  - When a 1% backdoor trigger is injected into a sample image dataset (e.g., MNIST/CIFAR),
    the system flags >90% of tainted batches within 2 epochs and places training in
    hold-safe mode with a signed attestation.
  - On a distributed multi-GPU job, gradient clipping violations and activation clustering
    anomalies are detected without leaking raw sample content; all telemetry is encrypted
    and keys are rotated.
  - With shadow mode enabled, no training interruptions occur; upon policy switch
    to enforce, the system halts on threshold breach and rolls back to the last verified
    checkpoint.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/train_sentinel.py
  - tests/test_aisec_005.py
  max_changed_lines: 500
- id: CLOUD-006
  title: SaaS Connector Egress Auditor
  category: cloud
  description: Continuously audits SaaS integrations (e.g., Slack/Google Workspace/Salesforce)
    by deploying scoped honey artifacts and canary tokens, validating OAuth scopes/redirects,
    simulating policy-constrained exports, and detecting cross-tenant or unsanctioned
    egress with remediation-as-code and signed evidence bundles.
  security_requirements:
  - Use isolated test tenants and least-privilege OAuth apps; never alter production
    artifacts; rate-limit API calls and enforce time-bounded token lifetimes and automatic
    revocation.
  - Cryptographically seal honey artifacts and telemetry (Sigstore/Rekor) and store
    secrets in a vault; strict RBAC and immutable audit logs.
  - 'Non-destructive validation: read-only checks by default with optional, explicit,
    policy-gated remediation (scope tightening, webhook quarantine) requiring human
    approval.'
  acceptance_tests:
  - A mis-scoped Slack app with files:read across all workspaces is detected after
    a planted honey document access; the tool correlates the access path and emits
    a signed incident report.
  - A simulated connector attempts to exfiltrate a honey token via an external webhook;
    the auditor verifies that DLP/policy blocks the egress or raises a high-severity
    finding if not.
  - Token rotation occurs for test apps; the auditor confirms revocation, removes
    stale grants, and validates no residual access using replay attempts logged as
    blocked.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/saas_connector_egress_auditor.py
  - tests/test_cloud_006.py
  max_changed_lines: 500
- id: HUNT-003
  title: 'IdP Attack Pattern Hunter: MFA Fatigue, AiTM & Consent Abuse'
  category: threat_hunting
  description: Correlates IdP (Okta/AzureAD/Google) and endpoint/network logs to detect
    MFA fatigue/push-bombing, adversary-in-the-middle (Evilginx) token theft, device-code
    phishing, and OAuth consent-grant abuse using temporal/graph analytics; guides
    response with human-in-the-loop playbooks and signed incident bundles.
  security_requirements:
  - Read-only ingestion from IdP and EDR/SIEM sources by default; response actions
    are optional and require explicit policy and human approval with full audit trails.
  - PII minimization and field-level encryption for sensitive attributes; enforce
    retention and access controls with tamper-evident logging.
  - Deterministic detection policies plus ML-assisted heuristics with versioned rulepacks
    and cryptographically signed detections/evidence.
  acceptance_tests:
  - Simulated MFA fatigue shows >20 push prompts in 10 minutes from new ASN/IPs culminating
    in an approval; the hunter raises a high-confidence alert and proposes a step-up
    auth + session reset playbook.
  - AiTM pattern with mismatched device fingerprint and anomalous token issuer is
    detected; the system identifies suspected token replay and prepares a signed containment
    bundle for session revocation.
  - A newly created OAuth app requests high-risk scopes and gains consent from a single
    user; the hunter flags consent abuse, correlates unusual API calls, and recommends
    admin review with one-click quarantine (if enabled).
  ready: true
  status: needs_work
  area_allowlist:
  - tools/threat_hunting/idp_attack_pattern_hunter.py
  - tests/test_hunt_003.py
  max_changed_lines: 500
- id: AI_SECURITY-006
  title: 'RAGShield: Data Poisoning & Retrieval Integrity Auditor'
  category: ai_security
  description: Audits and protects RAG pipelines by scanning corpora and vector indexes
    for poisoning/backdoors, enforcing signed-source retrieval, embedding drift detection,
    citation hashing, and prompt-injection sanitization with safe tool execution.
  security_requirements:
  - Content provenance enforcement with per-document SHA-256, signed manifests (Sigstore/in-toto),
    and transparency log inclusion checks.
  - Sandboxed tool/connectors with strict allowlists; HTML/Markdown sanitization and
    link/domain validation to neutralize prompt-injection-in-data.
  - Embedding anomaly/poison detectors (spectral signatures, k-NN outlier scores,
    watermark/backdoor trigger scans) with quarantine and signed attestations.
  acceptance_tests:
  - Inject a poisoned knowledge-base document containing a prompt-injection payload;
    tool flags and quarantines it, and RAG responses exclude the tainted source.
  - Simulate index tampering that shifts embedding clusters; tool detects drift, fails
    the policy gate, and emits a signed attestation with diffed cluster metrics.
  - RAG output cites a document whose stored hash mismatches current content; tool
    blocks response, records incident with provenance details, and alerts.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/ragshield_auditor.py
  - tests/test_ai_security_006.py
  max_changed_lines: 500
- id: VULN-003
  title: 'HermeticBuild Watchdog: CI/CD Script Behavior Sandbox'
  category: vulnerability
  description: Sandboxes package build/install scripts (npm/pip/cargo) in hermetic
    containers to detect malicious behaviors (network egress, credential access, supply-chain
    implants) using syscall tracing, egress allowlists, and SBOM/hash diffing before
    publish/deploy.
  security_requirements:
  - Deterministic, hermetic build sandbox with mount/user namespaces, read-only host
    mounts, no network by default, and reproducible seeds.
  - Behavior policy engine with seccomp/syscall profiles, file/secret access guards
    (block ~/.ssh, cloud metadata, token files), and egress allowlists.
  - Artifact integrity via SBOM (SPDX/CycloneDX) + hash diffing; signed attestations
    on pass and automatic quarantine on policy violations.
  acceptance_tests:
  - A malicious npm postinstall script attempts to curl a remote miner binary; tool
    blocks egress, captures syscall/network trace, and raises a high-severity violation.
  - A Python setup.py tries to read AWS credentials from environment and ~/.aws; access
    is denied, event is logged with file paths, and build is quarantined.
  - A legitimate cargo build with registry access on an allowlisted domain completes,
    produces an SBOM, and emits a Sigstore-signed attestation.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/vulnerability/hermetic_build_watchdog.py
  - tests/test_vuln_003.py
  max_changed_lines: 500
- id: CRYPTO-002
  title: 'PQ-Migrate Auditor: Post-Quantum Readiness Scanner & TLS Hybrid Probe'
  category: cryptography
  description: Inventories cryptographic usage across code and infrastructure, probes
    TLS endpoints for PQC/hybrid KEM support (e.g., Kyber/Dilithium variants), maps
    migration blockers, and generates policy-as-code remediations and staged canary
    rollouts.
  security_requirements:
  - Static and binary analysis to inventory crypto primitives, key sizes, and providers;
    flag weak/legacy algorithms and non-compliant usages (e.g., SHA-1, RSA-1024).
  - Active TLS probing for PQ/hybrid KEMs and signature algorithms; generate fallback-safe
    configuration templates and verify fixes in subsequent scans.
  - Change control with canary testing, HSM/KMS integration for key management, and
    Sigstore-signed readiness reports stored in a transparency log.
  acceptance_tests:
  - Scan a repository using RSA-1024 and SHA-1; tool outputs prioritized remediation
    with code locations and safer algorithm replacements.
  - Probe a set of TLS servers lacking hybrid KEM; tool suggests configuration changes,
    then confirms hybrid support after applying updates.
  - Generate a signed (Sigstore) PQ-readiness report and verify inclusion in a transparency
    log with tamper-evident metadata.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cryptography/pq_migrate_auditor.py
  - tests/test_crypto_002.py
  max_changed_lines: 500
- id: AI_SECURITY-007
  title: 'ToolForge Auditor: LLM Tool/Plugin Supply Chain Guard'
  category: ai_security
  description: Audits LLM tools/plugins (function-call adapters, LangChain tools,
    HTTP connectors) by verifying signatures, generating SBOMs, sandboxing install/execute
    phases to detect malicious behaviors, enforcing network egress allowlists, and
    emitting signed attestations for CI/CD gates.
  security_requirements:
  - Hermetic sandbox with seccomp/AppArmor and eBPF tracing; enforce filesystem RO
    mounts and network egress allowlists per tool manifest.
  - Verify supply-chain integrity using Sigstore (cosign) and generate SPDX/CycloneDX
    SBOMs with pinned hashes and vulnerability correlation.
  - Emit cryptographically signed, tamper-evident attestations (in-toto) and redact
    secrets; never persist credentials beyond session.
  acceptance_tests:
  - Given a plugin manifest with an unpinned dependency, the auditor fails policy
    and reports SBOM diff and remediation to pin exact versions.
  - When a tool attempts unexpected outbound DNS/HTTP during dynamic analysis, the
    sandbox blocks it, records eBPF evidence, and produces a signed incident bundle.
  - For a tool release signed by a trusted key, the auditor verifies Rekor inclusion,
    generates an SBOM, and passes with a signed attestation artifact.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/toolforge_auditor.py
  - tests/test_ai_security_toolforge_auditor.py
  max_changed_lines: 500
- id: CLOUD-007
  title: 'Metasurf Watch: IMDS/SSRF Exposure Scanner & Canary'
  category: cloud
  description: Continuously audits AWS/Azure/GCP workloads for SSRF paths to metadata
    services, validates IMDS hardening (tokens/hop limits/endpoint policies), deploys
    scoped honey IMDS endpoints and canary credentials, correlates cloud logs for
    abuse, and provides remediation-as-code.
  security_requirements:
  - Perform safe, rate-limited probes; never request sensitive real metadata and prefer
    simulated or canary endpoints with least-privilege scopes.
  - Cryptographically sign findings with timestamps and workload identity proofs;
    store evidence in write-once buckets with retention policies.
  - Auto-rotate and immediately revoke any triggered canary credentials; never exceed
    principle of least privilege for detectors and remediation.
  acceptance_tests:
  - Detect an EC2 instance with IMDSv1 enabled and hop limit > 1; emit high-severity
    finding with Terraform/CLI remediation steps.
  - When a container SSRF attempts 169.254.169.254 or metadata.google.internal, the
    sensor blocks/flags access, ties it to the originating pod, and opens a ticket
    with blast-radius analysis.
  - Upon canary token usage observed in CloudTrail/Activity Logs, trigger quarantine
    workflow (network isolate tag) and produce a signed evidence bundle including
    source IP and user agent.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/metasurf_watch.py
  - tests/test_cloud_metasurf_watch.py
  max_changed_lines: 500
- id: IOT-005
  title: 'EdgeVision Guard: Smart Camera Model Backdoor & Egress Auditor'
  category: iot
  description: Analyzes smart/edge camera firmware and on-device AI models to detect
    backdoors/trigger patches via spectral signatures and activation clustering, builds
    SBOMs with CVE mapping, emulates runtime to observe network egress and secret
    usage, and outputs signed, court-ready evidence.
  security_requirements:
  - Run firmware and model analysis in a network-shaped, microsegmented sandbox; enforce
    safe fuzzing with rate limits to avoid impacting production devices.
  - Produce cryptographically sealed evidence bundles (PCAP, model stats, screenshots)
    with chain-of-custody metadata and reproducible hashes.
  - Respect privacy by masking PII in captured frames/logs and require explicit operator
    consent before any live device interaction.
  acceptance_tests:
  - Extract SBOM from firmware image, correlate dependencies to CVEs, and flag hardcoded
    credentials with recommended mitigations.
  - Identify a backdoored object-detection model whose trigger patch causes systematic
    misclassification; produce trigger saliency and confidence shift report.
  - During emulated runtime, detect unauthorized RTSP/HTTPS egress to third-party
    endpoints, block connections within the sandbox, and generate a signed incident
    report.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/iot/edgevision_guard.py
  - tests/test_iot_edgevision_guard.py
  max_changed_lines: 500
- id: AI_SECURITY-008
  title: Deepfake Provenance & Watermark Sentinel
  category: ai_security
  description: Audits images, audio, and video for C2PA provenance, robust/invisible
    watermarks, and model fingerprint signatures; verifies cryptographic attestations,
    detects tampering/inconsistencies, and enforces policy gates to prevent deepfake-driven
    fraud and misinformation.
  security_requirements:
  - Verify C2PA/manifests and embedded signatures against trusted roots with transparency
    log inclusion where available; cryptographically sign audit outcomes.
  - Process media without retaining biometric features or PII; default to on-device
    or ephemeral analysis with secure deletion and configurable redaction of metadata.
  - Provide policy-as-code enforcement (quarantine/block/flag) with egress allowlists
    and reproducible, signed attestations for CI/CD and content publishing workflows.
  acceptance_tests:
  - Validate that a media asset with a valid C2PA manifest chains to a trusted root,
    passes signature checks, and is marked 'verified' with a signed audit record.
  - Detect and flag a video where watermark/fingerprint signals are inconsistent across
    frames (possible splicing/tamper), producing a high-confidence alert without leaking
    PII.
  - Block outbound publishing of media lacking provenance that also triggers deepfake
    heuristics (lip-sync mismatch, spectral artifacts) and emit a signed, timestamped
    policy decision.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/deepfake_provenance_sentinel.py
  - tests/test_ai_security_008.py
  max_changed_lines: 500
- id: NET-003
  title: 'DNSCovert Hunter: Encrypted DNS Covert Channel Detector'
  category: network
  description: Detects covert data exfiltration over DoH/DoT/ODoH by modeling resolver
    fingerprints, entropy and subdomain length distributions, flow timing, and JA3/JA4
    deltas; correlates SNI/ECH metadata and CDN domain-fronting anomalies with enterprise
    allowlists.
  security_requirements:
  - Operate passively without decrypting payloads; store only flow-level features
    and anonymized host metadata to preserve privacy.
  - Support strict resolver allowlists and baseline modeling to minimize false positives;
    rate-limit alerts and provide explainable feature attributions.
  - Sign flow summaries and model/version metadata; support reproducible detection
    reports with integrity verification.
  acceptance_tests:
  - Identify sustained high-entropy DoH POST traffic to a non-approved resolver with
    anomalous subdomain length distributions and raise a covert-channel alert.
  - Baseline approved OS/browser DoH resolvers and confirm no alerts are generated
    during normal browsing across diverse sites for 24 hours.
  - Detect domain-fronted DoH via CDN where SNI/CDN host mismatches destination resolver
    identity and JA3/JA4 fingerprints shift mid-session, producing a high-confidence
    alert.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/network/dnscovert_hunter.py
  - tests/test_network_003.py
  max_changed_lines: 500
- id: FORENSICS-005
  title: 'TrustAnchor Forensic Attestor: TPM/TEE Evidence Collector'
  category: forensics
  description: Performs low-impact acquisition and verification of TPM quotes (PCR/IMA),
    measured boot logs, and TEE attestation reports (TDX/SEV-SNP/SGX/TrustZone); validates
    vendor chains, correlates kernel/device state, and seals court-ready bundles with
    timestamps.
  security_requirements:
  - Collect evidence read-only with freshness nonces to prevent replay; verify against
    vendor attestation services and pinned certificate chains.
  - Cryptographically seal artifacts (logs, quotes, reports) with hash chains and
    RFC 3161 timestamps; maintain a signed chain-of-custody manifest.
  - Vendor- and cloud-agnostic support with explicit capability detection; fail closed
    on partial verification and surface verifiable reasons.
  acceptance_tests:
  - Acquire a TPM quote using a verifier-provided nonce; confirm PCR composite matches
    reconstructed values from the measured boot event log and that the EK/AK chain
    validates.
  - Collect a TEE report (e.g., TDX/SEV-SNP) and verify the report with the appropriate
    attestation service, failing the run on chain or policy mismatches.
  - Produce a sealed evidence bundle (quotes, event logs, verifier policy, timestamps,
    and signatures) that passes independent verification and integrity checks on a
    separate system.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/forensics/trustanchor_forensic_attestor.py
  - tests/test_forensics_005.py
  max_changed_lines: 500
- id: AI_SECURITY-009
  title: 'SynthGuard: Synthetic Data Leakage & Integrity Auditor'
  category: ai_security
  description: Audits synthetic data pipelines and generators for privacy leakage,
    provenance integrity, and watermark resilience by orchestrating canary seeding,
    membership-inference/model-inversion probes, dataset/model signature verification,
    and policy-gated releases with signed attestations.
  security_requirements:
  - Enforce signed provenance attestations (Sigstore/in-toto) for datasets, models,
    and generator plugins; block execution on verification failure.
  - Run leakage probes (canary prompts, membership inference, inversion) in sandboxed
    workers with strict rate/resource limits and egress allowlists.
  - Apply PII/PHI scanners and differential-privacy leakage thresholds to outputs;
    quarantine generators exceeding risk scores and emit signed audit reports.
  acceptance_tests:
  - "Seed unique canary records into a training set, generate N=10k samples, and detect\
    \ at least one canary leak with confidence \u2265 0.95; block release and produce\
    \ a signed incident bundle."
  - Verify dataset/model signatures against Rekor transparency log; on tampered artifact,
    prevent pipeline execution and record policy violation with reproducible evidence.
  - Run membership-inference suite on a target model and produce a quantitative leakage
    risk score; if score > policy threshold, quarantine the model and require manual
    approval.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/synthguard.py
  - tests/test_ai_security_009.py
  max_changed_lines: 500
- id: CLOUD-008
  title: 'KubeIdentity Tripwire: SA Token Abuse & Lateral Movement Auditor'
  category: cloud
  description: Continuously audits Kubernetes service account token posture and workload
    identity boundaries; deploys scoped honey service accounts and projected tokens,
    correlates API/audit logs to detect replay outside the cluster, flags overbroad
    RBAC/audiences, and auto-revokes abused credentials with signed, forensically
    sound alerts.
  security_requirements:
  - Use least-privileged, read-only RBAC for posture discovery; honey tokens are time-bound,
    namespace-scoped, and rotation-enabled.
  - Cryptographically sign honey credentials and alerts; automate revocation and evidence
    sealing upon detected misuse.
  - Respect network egress allowlists; no secret exfiltration beyond designated evidence
    sink with encryption-at-rest and access controls.
  acceptance_tests:
  - Create a honey service account with projected token; simulate token replay from
    an external IP and detect via API/audit log correlation, triggering auto-revocation
    and a signed alert within 60 seconds.
  - Scan cluster and report pods with automountServiceAccountToken=true in restricted
    namespaces, providing least-privilege RBAC and automount remediation diffs.
  - Identify projected token audiences that are overly broad or missing; recommend
    constrained audiences and validate fix through re-scan.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/cloud/kubeidentity_tripwire.py
  - tests/test_cloud_008.py
  max_changed_lines: 500
- id: FORENSICS-006
  title: 'LambdaTrace: Serverless Ephemeral Forensic Snapshotter'
  category: forensics
  description: Performs low-impact, on-invocation capture of ephemeral serverless
    evidence (env/process metadata, tmpfs artifacts, eBPF-lite syscall summaries,
    and network flow headers) across AWS/Azure/GCP; seals bundles with timestamps,
    correlates with provider logs, and preserves chain-of-custody for incident response.
  security_requirements:
  - Minimize performance impact via configurable sampling, cold-start-only hooks,
    and rate-limited evidence capture with backpressure controls.
  - Seal evidence bundles using cryptographic timestamps and signatures; store in
    WORM-capable, access-controlled archives with transparent integrity logs.
  - Apply PII-safe redaction policies and scope captures to metadata and non-content
    payload summaries to avoid data privacy violations.
  acceptance_tests:
  - "Invoke a test function under load (concurrency \u2265 50); capture env variables\
    \ (filtered), tmpfs summaries, stdout/stderr, and network 5-tuples; generate a\
    \ sealed evidence bundle with verifiable signatures and timestamps."
  - Validate that bundle integrity checks (hash/signature) pass after transfer to
    archival storage; any tampering must be detected and reported.
  - "Measure end-to-end overhead: median p95 latency increase \u2264 5% and error\
    \ rate increase \u2264 0.1% with capture enabled under defined workload; auto-throttle\
    \ engages when thresholds are exceeded."
  ready: true
  status: needs_work
  area_allowlist:
  - tools/forensics/lambdatrace_snapshotter.py
  - tests/test_forensics_006.py
  max_changed_lines: 500
- id: AI_SECURITY-010
  title: 'PromptLeak Trap: LLM Memory Honeypot & Egress Auditor'
  category: ai_security
  description: Deploys decoy secrets and canary PII inside LLM context/tool memory,
    enforces signed-source retrieval and egress allowlists for tools/plugins, detects
    prompt-injection-led data exfiltration and memory scraping, and emits signed,
    forensically sound alerts with reproducible attestations.
  security_requirements:
  - All tool/plugin executions must run in a sandbox with default-deny network egress
    and capability auditing, producing immutable execution transcripts.
  - RAG sources and documents must be signature-verified (Sigstore/in-toto) and hash-pinned
    before retrieval or indexing.
  - Canary secrets/PII are unique per deployment, non-sensitive, and generate tamper-evident,
    signed alerts upon access or attempted exfiltration.
  acceptance_tests:
  - When a canary token placed in the LLM context is accessed by a plugin, the system
    blocks outbound requests not on the allowlist and produces a signed alert with
    tool execution transcript.
  - A query that attempts to use an unsigned or hash-mismatched RAG document is denied,
    with a policy violation recorded and a detailed attestation emitted.
  - A prompt-injection that instructs a tool to fetch an external URL outside the
    allowlist is prevented; the attempt is logged with a redaction summary and evidence
    bundle.
  ready: true
  status: needs_work
  area_allowlist:
  - tools/ai_security/promptleak_trap.py
  - tests/test_ai_security_010.py
  max_changed_lines: 500
- id: CLOUD-009
  title: 'KeyTrace Guardian: Cross-Cloud KMS Misuse & Envelope Abuse Auditor'
  category: cloud
  description: Audits AWS/Azure/GCP KMS usage for misuse and data exfil via decrypt/encrypt
    patterns, validates key policies and cross-account grants, plants signed canary
    ciphertexts across regions, correlates audit logs for anomalous decrypts, and
    recommends least-privilege remediations with signed findings.
  security_requirements:
  - Use least-privilege, read-only roles; write only to dedicated evidence stores
    encrypted with customer-managed keys and immutable logging.
  - Issue per-region, per-account signed canary ciphertexts that contain no real data
    and are rotated regularly; verify usage via provider audit logs.
  - Enforce policy-as-code checks for key policies, grants, rotation, and alias hygiene;
    detect wildcard principals and unintended cross-account access.
  acceptance_tests:
  - A KMS key policy granting a wildcard principal is flagged with a high-severity
    finding and a proposed least-privilege remediation plan.
  - A decrypt API call on a canary ciphertext in CloudTrail/Azure Activity Log/GCP
    Audit Log generates an immediate signed alert with the calling principal and source
    IP.
  - A non-rotating KMS key with mismatched alias across regions is detected and reported
    with drift details and remediation steps.
  ready: true
  status: in_progress
  area_allowlist:
  - tools/cloud/keytrace_guardian.py
  - tests/test_cloud_009.py
  max_changed_lines: 500
- id: THREAT_HUNTING-004
  title: 'ShadowPipeline Hunter: Client-Side Supply Chain Beacon Detector'
  category: threat_hunting
  description: Detects compromised third-party web scripts and client-side supply-chain
    beacons using headless browser instrumentation, CSP/SRI validation, JS AST diffing,
    and CDN path typosquat detection; deploys canary DOM fields to bait skimmers and
    emits sealed evidence bundles (HTML snapshots, PCAP, console logs).
  security_requirements:
  - Headless crawlers run in isolated sandboxes with constrained network egress; all
    traffic is captured and hashed with timestamps for integrity.
  - Validate SRI/CSP policies, enforcing strong hashes and allow-listed script sources;
    block execution of unsigned or hash-mismatched scripts in test harnesses.
  - Produce signed, tamper-evident evidence bundles containing DOM snapshots, request/response
    metadata, and console/network logs.
  acceptance_tests:
  - A simulated Magecart-style skimmer exfiltrating a canary form field is detected;
    the alert includes PCAP, DOM snapshot of the injected script, and a signed evidence
    manifest.
  - A third-party script with an SRI hash mismatch is blocked in the analysis environment
    and raises a policy violation with the expected vs. observed hash.
  - A typosquatted CDN URL (e.g., slight domain variation) is identified via fuzzy
    matching and reputation feeds, generating a medium-severity finding with suggested
    blocklist updates.
  ready: true
  status: todo
  area_allowlist:
  - tools/threat_hunting/shadowpipeline_hunter.py
  - tests/test_threat_hunting_004.py
  max_changed_lines: 500
- id: AI_SECURITY-011
  title: 'FineTune Sentinel: Hosted Finetune Leakage & Provenance Auditor'
  category: ai_security
  description: Audits hosted fine-tuning jobs across cloud/SaaS LLM services for dataset
    provenance, PII leakage, membership-inference risk, and model theft; instruments
    job telemetry and evaluates outputs with canary prompts, drift checks, and policy
    gates; emits signed, reproducible attestations and can quarantine risky promotions.
  security_requirements:
  - Default read-only via provider APIs; collect only hashed metadata/metrics (no
    raw PII) and store evidence with encryption-at-rest and role-scoped access.
  - Enforce egress allowlists for evaluation tools/prompts; sign findings and policy
    decisions using Sigstore (Fulcio/Rekor) with time-stamped attestations.
  - Require dataset hash manifests and provenance attestations; block runs on mismatch
    via OPA policies with reproducible replay inputs.
  acceptance_tests:
  - When a canary record seeded in the training set appears in model outputs during
    evaluation, the tool blocks promotion and emits a signed attestation.
  - A fine-tune job with missing or mismatched dataset hash/provenance is prevented
    from starting and a policy violation report is generated.
  - Membership inference risk score above a configurable threshold triggers quarantine
    of the model artifact and a reproducible evidence bundle is stored.
  ready: true
  status: todo
  area_allowlist:
  - tools/ai_security/finetune_sentinel.py
  - tests/test_ai_security_011.py
  max_changed_lines: 500
- id: CLOUD-010
  title: 'ArtifactGraph Guard: Cross-Cloud Registry Replication & Signature Enforcer'
  category: cloud
  description: Builds a graph of container/model/package registries and replication
    policies across AWS ECR, GCP Artifact Registry, Azure ACR, Docker Hub, and HuggingFace;
    detects public exposure, tag squatting, unsigned artifacts, and OIDC/webhook trust
    drift; enforces cosign/Sigstore verification on pull/promotion and validates guardrails
    via namespaced canary replications.
  security_requirements:
  - Operate read-only by default; remediation actions require explicit approval and
    scoped, least-privilege credentials with change logs.
  - Verify signatures and provenance attestations (cosign/Sigstore, SLSA, in-toto)
    and block unsigned/unchained promotions with Rekor inclusion checks.
  - Use namespaced, time-limited canary artifacts for policy validation; auto-cleanup
    enabled and no deletion of customer artifacts without opt-in.
  acceptance_tests:
  - Unsigned images in a protected repository are identified and promotion requests
    are failed with a detailed signed report and remediation steps.
  - A replication rule that exposes a private registry to a public target is detected
    and escalated as a critical misconfiguration with blast-radius mapping.
  - Cross-cloud replication using OIDC/webhooks with audience/issuer mismatch is flagged
    and blocked pending trust-policy correction.
  ready: true
  status: todo
  area_allowlist:
  - tools/cloud/artifactgraph_guard.py
  - tests/test_cloud_010.py
  max_changed_lines: 500
- id: MOBILE-002
  title: Baseband & eSIM Attack Surface Auditor
  category: mobile
  description: Audits Android/iOS and MDM configs for baseband/eSIM/SIM Toolkit risks
    including WAP Push/CP, Class 0/Flash/Silent SMS, UICC applet permissions, carrier
    configuration profiles, and IMS/VoLTE edge cases; simulates benign canary messages
    in lab mode, detects downgrade/roaming abuse, and produces sealed, privacy-preserving
    evidence.
  security_requirements:
  - Leverage userland/MDM APIs only; no baseband firmware modifications; apply strict
    rate limits for any radio interactions and support lab-only simulation.
  - Emulate STK commands and WAP Push using isolated test IMSIs in lab mode; never
    transmit real subscriber data or alter carrier settings in production.
  - Cryptographically seal findings with timestamps; capture only metadata in production
    and require explicit consent to collect payloads in lab settings.
  acceptance_tests:
  - Devices accepting WAP Push without user consent are detected and an MDM/carrier
    configuration remediation is recommended with a sealed evidence record.
  - An MDM profile permitting silent/flash SMS is flagged with a hardening baseline
    and a validation script to enforce stricter settings.
  - Canary Class 0 SMS in production are blocked (no user-visible disruption) and
    the event is logged with signed, forensically sound telemetry.
  ready: true
  status: todo
  area_allowlist:
  - tools/mobile/baseband_esim_auditor.py
  - tests/test_mobile_002.py
  max_changed_lines: 500
- id: NET-004
  title: MASQUE/HTTP3 Covert Proxy Exfil Hunter
  category: network
  description: "Detects covert data exfiltration and tunneling over MASQUE, HTTP/3\
    \ CONNECT-UDP/CONNECT-IP, and enterprise-bypassing QUIC proxies by profiling handshake/tunnel\
    \ semantics, QPACK/headers, spin-bit/timing features, endpoint fingerprints, and\
    \ policy drift\u2014without decrypting payloads."
  security_requirements:
  - Operate passively on metadata only (no payload decryption); hash sensitive identifiers
    with rotating, HSM-protected salts to preserve privacy.
  - Maintain signed, versioned detection rules/models and integrity-verified endpoint
    fingerprints (Sigstore/Rekor attestations).
  - Emit forensically sound alerts with clock-synchronized timestamps (Roughtime/RFC3161)
    and sealed evidence bundles (PCAP headers, JA4/JA4S, flow stats).
  acceptance_tests:
  - When a host initiates HTTP/3 CONNECT-UDP to a MASQUE-capable origin, the system
    classifies the flow as a tunnel and emits a high-confidence alert with supporting
    QUIC/MASQUE indicators.
  - Legitimate QUIC web traffic (non-CONNECT tunnels) is not flagged, keeping false
    positives under a defined threshold on a clean baseline capture.
  - If an allowlisted enterprise MASQUE egress is used within policy, the system records
    the event but suppresses alerts while still sealing minimal evidence for audit.
  ready: true
  status: todo
  area_allowlist:
  - tools/network/masque_exfil_hunter.py
  - tests/test_net_004.py
  max_changed_lines: 500
- id: CLOUD-011
  title: 'AuditLog Tamper Sentinel: Cross-Cloud Integrity & Gap Detector'
  category: cloud
  description: Continuously verifies integrity, completeness, and retention of AWS/Azure/GCP
    control-plane and data-plane audit logs by validating digest chains (e.g., CloudTrail
    Digest), storage immutability (Object Lock/WORM), sequence/timestamp continuity,
    and policy drift; anchors proofs to external timestamping and emits sealed, court-ready
    findings.
  security_requirements:
  - Use read-only, least-privilege roles; verify log object immutability and bucket/container
    policies on every run; alert on drift or retroactive changes.
  - Validate provider-signed digests/manifest chains and cross-verify with external
    timestamp authorities (RFC3161) and transparency logs (Rekor).
  - Seal evidence bundles with cryptographic signatures, include NTP/chrony health,
    and store in an immutable archive with rotation and key separation (KMS/HSM).
  acceptance_tests:
  - If a CloudTrail digest mismatch or missing digest interval is detected, the system
    raises a critical alert with the exact affected time window and verification artifacts.
  - When retention or object-lock policies are weakened (e.g., reduced retention,
    disabled legal hold), the system flags policy drift and proposes remediation-as-code.
  - On buckets/containers where logs are intact and policy-compliant, the system produces
    a signed attestation proving continuity and immutability for the audited period.
  ready: true
  status: todo
  area_allowlist:
  - tools/cloud/auditlog_tamper_sentinel.py
  - tests/test_cloud_011.py
  max_changed_lines: 500
- id: AI_SECURITY-012
  title: 'GenCode Risk Auditor: AI-Generated Code Supply Chain Scanner'
  category: ai_security
  description: Analyzes pull requests and CI artifacts to detect risky AI-generated
    code patterns (unsafe eval/deserialize, prompt-injection sinks, insecure crypto,
    SSRF/XSS/SQLi), correlates dependency diffs with typosquat/confusion risks, sandboxes
    suspicious snippets with egress allowlists, and produces signed SBOMs and policy-gated
    risk attestations.
  security_requirements:
  - "Perform static analysis locally; never upload proprietary code\u2014use offline\
    \ rules/models or approved on-prem inference; scrub PII and secrets from reports."
  - Execute dynamic/snippet tests only in hermetic sandboxes with network egress allowlists,
    syscall tracing, and artifact hashing; forbid credential access.
  - Sign all outputs (risk reports, SBOMs, provenance) and verify third-party rulepacks/plugins
    via Sigstore; maintain reproducible scans with pinned dependencies.
  acceptance_tests:
  - A PR introducing an unsafe eval plus outbound fetch to an unapproved domain is
    blocked with a high-risk finding and sandbox transcript showing prevented egress.
  - A dependency change to a typosquatted package is detected and the pipeline fails
    with remediation guidance and a signed attestation citing the offending artifact.
  - On a clean repository, the tool emits a low-risk verdict, a signed CycloneDX SBOM,
    and a provenance attestation suitable for CI policy gates.
  ready: true
  status: todo
  area_allowlist:
  - tools/ai_security/gencode_risk_auditor.py
  - tests/test_ai_security_012.py
  max_changed_lines: 500
- id: AI_SECURITY-013
  title: 'SideChannel Guard: ML Timing/Cache Egress Monitor'
  category: ai_security
  description: Profiles ML training/inference for side-channel leakage via timing,
    cache activity, and GPU/CPU perf counters; orchestrates differential input fuzzing
    to quantify leakage, enforces constant-time padding and noise strategies, and
    emits signed, reproducible attestations for CI/CD gates.
  security_requirements:
  - Use least-privilege eBPF/perf access with explicit user consent; collect only
    aggregate, non-content telemetry (no model weights or raw inputs).
  - Store telemetry encrypted at rest; block outbound network by default and require
    explicit egress allowlists for any remote reporting.
  - Produce signed leakage attestations (e.g., in-toto/Sigstore) including environment
    hashes (driver/kernel/tooling) and reproducible test vectors.
  acceptance_tests:
  - Introduce a synthetic data-dependent branch in a PyTorch model; tool detects timing
    variance above threshold and raises LEAKAGE_TIMING with supporting metrics.
  - Enable constant-time padding mitigation; leakage score falls below policy threshold
    and no alert is emitted for the same workload.
  - Generate an attestation bundle containing leakage score, environment hashes, and
    signed provenance; signature verification succeeds with the configured trust root.
  ready: true
  status: todo
  area_allowlist:
  - tools/ai_security/sidechannel_guard.py
  - tests/test_ai_security_013.py
  max_changed_lines: 500
- id: CLOUD-012
  title: 'WebhookShield: SaaS/CI Webhook Trust Drift Auditor'
  category: cloud
  description: Audits and protects inbound webhooks for CI/CD and SaaS integrations
    by validating HMAC/mTLS signatures, timestamps and nonces, IP/CN pinning, and
    schema diffs; deploys honey webhooks to detect replay and credential leakage;
    auto-rotates secrets and enforces policy-as-code with immutable, timestamped logs.
  security_requirements:
  - Enforce signature verification (HMAC/mTLS), strict clock skew windows, and one-time
    nonces to prevent replay and trust drift.
  - Maintain append-only, hash-chained audit logs with external timestamping/anchoring
    for forensic integrity.
  - Quarantine honey endpoint hits, auto-rotate shared secrets/keys safely, and emit
    signed incident artifacts without disrupting legitimate flows.
  acceptance_tests:
  - Replay a captured webhook outside the allowed time window; request is rejected
    and REPLAY_DETECTED is logged with source IP and signature details.
  - Send a webhook with an invalid signature; tool fails closed, emits SIGNATURE_INVALID,
    and stores a sealed forensic bundle (headers, hash, verification trace).
  - Trigger a honey webhook from an untrusted origin; tool rotates the secret, blocks
    the source, and opens a tracked incident with signed evidence.
  ready: true
  status: todo
  area_allowlist:
  - tools/cloud/webhookshield.py
  - tests/test_cloud_012.py
  max_changed_lines: 500
- id: IOT-006
  title: 'LPWANGuard: LoRaWAN Key & Replay Auditor'
  category: iot
  description: "Analyzes LoRaWAN OTAA/ABP traffic and device inventories to detect\
    \ AppKey reuse, weak/\u91CD\u590D DevNonce patterns, MIC failures, and replay\
    \ risk; performs lab-safe join simulations, validates ADR/MAC command hardening,\
    \ supports SDR captures and gateway logs, and emits sealed, privacy-preserving\
    \ reports."
  security_requirements:
  - Default to passive RF monitoring; allow active tests only in lab mode with configured
    duty-cycle, frequency plan, and power limits to ensure regulatory compliance.
  - Prohibit key brute-forcing; verify keys only against provided inventories and
    cryptographic checks; redact DevEUI/AppEUI in outputs by default.
  - Seal evidence bundles (PCAP excerpts, join transcripts, key fingerprints) with
    hash chains and trusted timestamps for forensic soundness.
  acceptance_tests:
  - Observe multiple OTAA joins with repeated DevNonce for the same DevEUI; tool flags
    REPLAY_RISK and references supporting frames in the sealed bundle.
  - Identify an ABP device using default/known NwkSKey/AppSKey patterns from inventory;
    tool recommends OTAA migration and key rotation with concrete steps.
  - Attempt active transmission without lab mode configuration; tool refuses to transmit
    and records a LAB_MODE_REQUIRED safety error.
  ready: true
  status: todo
  area_allowlist:
  - tools/iot/lpwan_guard.py
  - tests/test_iot_006.py
  max_changed_lines: 500
- id: CLOUD-013
  title: 'MeshGuard: Service Mesh Identity & Egress Drift Auditor'
  category: cloud
  description: Continuously audits Kubernetes service meshes (Istio/Linkerd/Kuma)
    for mTLS/SPIFFE identity drift, egress bypasses, and policy regressions; deploys
    namespaced canary workloads, validates SDS cert chains, and enforces policy-as-code
    with signed attestations.
  security_requirements:
  - Zero-impact, namespace-scoped canary deployments with deny-by-default egress and
    time-bounded credentials.
  - Read-only access to cluster resources; no disruptive policy changes without dry-run
    and explicit approval.
  - Signed, immutable logs and attestations (Sigstore/Rekor) with privacy-preserving
    metadata.
  acceptance_tests:
  - Detects misconfigured AuthorizationPolicy allowing unintended cross-namespace
    calls; emits finding with call graph and SPIFFE IDs.
  - Identifies egress traffic bypassing the mesh via node-level routes and flags workloads
    lacking sidecars; recommends NetworkPolicy and egress gateway fixes.
  - Validates SDS-issued cert rotation continuity and raises alert on trust bundle
    drift or expiration within a configurable threshold.
  ready: true
  status: todo
  area_allowlist:
  - tools/cloud/meshguard.py
  - tests/test_cloud_013_meshguard.py
  max_changed_lines: 500
- id: AI_SECURITY-014
  title: 'EmbeddingLeak Auditor: Vector DB Inversion & Tenant Isolation Tester'
  category: ai_security
  description: Assesses vector databases (Pinecone/Weaviate/FAISS/OpenSearch) and
    RAG services for embedding inversion, membership inference, and cross-tenant data
    leakage; seeds signed canary embeddings, runs black-box inversion probes, and
    enforces isolation policies with reproducible attestations.
  security_requirements:
  - Operates only on approved test datasets with seeded canaries; no extraction from
    unowned tenants or production PII.
  - All attack simulations are rate-limited, logged, and sandboxed with network egress
    allowlists.
  - Results and SBOM/provenance for clients/SDKs are signed and anchored to transparency
    logs.
  acceptance_tests:
  - Successfully detects cross-namespace index exposure via mis-scoped API keys and
    confirms inability after policy fix.
  - Recovers seeded canary text from embeddings above a configured similarity threshold
    and seals an evidence bundle.
  - Flags an embedding API that returns training-time metadata enabling membership
    inference; provides redaction and configuration hardening recommendations.
  ready: true
  status: todo
  area_allowlist:
  - tools/ai_security/embedding_leak_auditor.py
  - tests/test_ai_security_014_embedding_leak.py
  max_changed_lines: 500
- id: FORENSICS-007
  title: 'WebWorkspace Forensic Collector: Browser Runtime Artifact Sealer'
  category: forensics
  description: 'Performs live, low-impact acquisition of browser/webapp runtime artifacts
    via the DevTools Protocol: service worker/CacheStorage, IndexedDB, localStorage,
    WASM modules, and WebRTC signaling/ICE fingerprints; produces cryptographically
    sealed, court-ready bundles.'
  security_requirements:
  - Attaches in read-only, throttle-safe mode to prevent script execution changes;
    no JS injection beyond DevTools fetch/DOM snapshot APIs.
  - Cryptographic sealing with timestamping and chain-of-custody metadata; reproducible
    acquisition playbooks.
  - PII minimization and structured redaction options for cookies/tokens unless explicitly
    authorized.
  acceptance_tests:
  - Captures service worker scripts and CacheStorage entries from a target origin
    and verifies hash consistency across two passes.
  - Extracts IndexedDB schema and records, redacts configured key patterns (e.g.,
    auth tokens), and emits a signed manifest.
  - Records WebRTC SDP offers/ICE candidates from a live session without media capture
    and correlates with network flow metadata.
  ready: true
  status: todo
  area_allowlist:
  - tools/forensics/webworkspace_collector.py
  - tests/test_forensics_007_webworkspace.py
  max_changed_lines: 500
- id: AI_SECURITY-015
  title: 'WeightWatch: Model Artifact Exfiltration & Registry Leak Hunter'
  category: ai_security
  description: Monitors and gates model artifact flows across registries (HuggingFace/S3/Artifact
    Registries) to detect unsigned weights, tag drift, abnormal pull patterns, and
    covert exfiltration. Seeds signed canary weight shards/watermarks, verifies Sigstore/cosign
    attestations, correlates egress logs with CI/CD provenance, and quarantines risky
    repositories with signed, reproducible alerts.
  security_requirements:
  - Operate with read-only scopes and scoped honey tokens; never alter production
    artifacts outside quarantined namespaces.
  - Verify all artifacts and promotions via Sigstore/cosign signatures and in-toto/SLSA
    attestations; block unsigned or provenance-missing tags.
  - Minimize data collection (no weight content storage); store only hashes, metadata,
    and signed audit trails with immutable timestamping.
  acceptance_tests:
  - Simulate an anomalous surge of pulls for a protected model tag from an unknown
    IP/identity; tool detects rate/geo/profile deviation, confirms missing/invalid
    signatures, and emits a signed incident bundle while temporarily quarantining
    the tag.
  - Seed a signed canary shard in a private bucket and attempt retrieval from a disallowed
    CIDR; tool detects access, validates the canary watermark, revokes the scoped
    token, and anchors the alert to transparency logs.
  - Attempt to promote an unsigned model revision to 'stable' in the registry; policy
    gate blocks promotion, citing failed cosign verification and missing in-toto provenance,
    with a remediation diff.
  ready: true
  status: todo
  area_allowlist:
  - tools/ai_security/weightwatch.py
  - tests/test_ai_security_015.py
  max_changed_lines: 500
- id: CLOUD-014
  title: 'GPUShield: Cloud GPU Isolation & Remanence Auditor'
  category: cloud
  description: Continuously validates GPU tenancy isolation (MIG/MPS/SR-IOV) and data
    remanence hygiene across multi-cloud fleets. Orchestrates controlled jobs that
    write signed canary patterns, then performs post-teardown VRAM/BAR1 residue scans,
    driver/firmware drift checks, device-plugin posture audits, and eBPF-lite telemetry
    correlation to detect cross-tenant leakage and misconfigurations.
  security_requirements:
  - Run canary workloads in isolated test namespaces/projects with enforced quotas
    and automated cleanup; never disrupt production training jobs.
  - Collect only integrity hashes, timing, and residue indicators; no capture of customer
    model/data content beyond synthetic canaries.
  - Produce signed attestations (Rekor anchoring) for each audit with reproducible
    environment manifests and hardware/driver fingerprints.
  acceptance_tests:
  - Launch two isolated tenants on shared GPUs with MIG enabled; write a canary pattern
    in tenant A, tear down, then scan from tenant B. No residue should be detected;
    any match triggers a critical leakage finding with signed evidence.
  - Detect GPU driver/firmware drift from baseline (e.g., vulnerable branch enabling
    MPS mixed security mode); generate policy-as-code remediation and prevent autoscaling
    nodes from admission until compliant.
  - Validate device-plugin hardening (no hostPath escape, proper cgroup/IOCTL filters);
    simulate a misconfiguration and confirm the auditor blocks risky scheduling and
    emits a detailed posture report.
  ready: true
  status: todo
  area_allowlist:
  - tools/cloud/gpushield.py
  - tests/test_cloud_014.py
  max_changed_lines: 500
- id: NET-005
  title: 'WebRTC Covert Channel Hunter: STUN/TURN Abuse & P2P Exfil IDS'
  category: network
  description: "A privacy-preserving IDS for detecting covert exfiltration over WebRTC.\
    \ Profiles ICE candidate patterns, STUN/TURN server fingerprints, DTLS-SRTP handshakes,\
    \ DataChannel timing/size entropy, and relay vs. direct flows to flag domain-fronted\
    \ TURN abuse, phantom signaling, and long-lived headless P2P tunnels\u2014without\
    \ decrypting payloads."
  security_requirements:
  - Perform metadata-only analysis (no media/content decryption) and hash/anonymize
    identifiers to preserve user privacy.
  - Maintain allowlists for sanctioned STUN/TURN and conferencing domains; adaptive
    baselining to minimize false positives.
  - Emit signed, forensically sound alerts with JA4/JA4S-like fingerprints, flow statistics,
    and reproducible detection rationale.
  acceptance_tests:
  - Replay traffic with long-lived TURN-relayed DTLS-SRTP carrying high-entropy, uniform-sized
    DataChannel frames to unsanctioned endpoints; tool flags covert exfil pattern
    and generates a signed incident report.
  - Initiate a normal corporate video call using approved STUN/TURN; ensure flows
    are baselined and not alerted after allowlist learning period, demonstrating low
    false positives.
  - Simulate domain-fronted TURN over TLS:443 to a non-approved IP range with atypical
    ICE retries and candidate churn; detector correlates fingerprints and raises an
    escalation with remediation guidance.
  ready: true
  status: todo
  area_allowlist:
  - tools/network/webrtc_covert_hunter.py
  - tests/test_net_005.py
  max_changed_lines: 500
- id: MOBILE-003
  title: 'SDK Sentry: Mobile SDK Supply Chain Beacon & Permission Auditor'
  category: mobile
  description: Audits embedded mobile SDKs for covert data egress, overbroad permissions,
    dynamic code loading, and tracker beacons. Combines static SBOM extraction and
    signature verification with emulator-based dynamic instrumentation (e.g., Frida/LLDB)
    to map runtime endpoints, seed signed canary identifiers, and emit sealed, reproducible
    findings.
  security_requirements:
  - Operate in sandboxed emulators with network egress allowlists; never collect real
    user PII or decrypt TLS without opt-in test certs.
  - Generate SDK SBOMs (SPDX/CycloneDX), verify signatures and certificate pinning
    bypass attempts, and correlate SDK versions with CVEs.
  - Produce cryptographically signed, timestamped audit logs and evidence bundles;
    preserve chain-of-custody with verifiable attestations.
  acceptance_tests:
  - Given an APK with a third-party analytics SDK, the tool identifies the SDK, builds
    an SBOM, and flags overbroad location/contacts permissions with CVE correlations.
  - During dynamic run, seeded canary identifiers are observed exfiltrating to a non-allowlisted
    endpoint, resulting in a high-confidence alert with sealed network evidence.
  - A benign app using approved SDKs and allowlisted domains completes analysis with
    no high-severity findings and all logs pass signature verification.
  ready: true
  status: todo
  area_allowlist:
  - tools/mobile/sdk_sentry.py
  - tests/test_mobile_003.py
  max_changed_lines: 500
- id: NET-006
  title: 'HTTP/2 Abuse Hunter: Rapid Reset & Stream Flood Detector'
  category: network
  description: A privacy-preserving IDS that detects HTTP/2 Rapid Reset, stream multiplexing
    floods, and SETTINGS/WINDOW_UPDATE abuse without decrypting payloads. Profiles
    connection semantics, RST_STREAM bursts, and timing patterns, correlates JA3/JA4
    fingerprints and WAF/CDN logs, and recommends targeted mitigations.
  security_requirements:
  - Passive, metadata-only collection (no payload decryption); minimize PII via hashing
    of IPs/domains and configurable retention.
  - Robust detection of RST_STREAM burst signatures, anomalous concurrency, and flow-control
    abuse with tunable thresholds to reduce false positives.
  - Emit signed, time-synchronized alerts with minimal PCAP snippets and header summaries
    suitable for forensics and compliance reporting.
  acceptance_tests:
  - A replayed Rapid Reset trace triggers a high-confidence alert with evidence including
    burst rate, stream IDs, and JA3/JA4 fingerprints.
  - High-concurrency but benign HTTP/2 workload (e.g., multiplexed API traffic) does
    not raise high-severity alerts under default thresholds.
  - Integration with WAF logs correlates attacker IP/ASN and produces an actionable
    mitigation recommendation (rate limit, rule signature) in the report.
  ready: true
  status: todo
  area_allowlist:
  - tools/network/http2_abuse_hunter.py
  - tests/test_network_006.py
  max_changed_lines: 500
- id: FORENSICS-008
  title: LLMChain Forensic Recorder & Evidence Sealer
  category: forensics
  description: 'On-demand capture and sealing of LLM application runtime artifacts:
    prompts (redacted), tool invocations, retrieval sources, environment/process metadata,
    and egress summaries. Provides framework hooks (OpenAI functions, LangChain, Semantic
    Kernel), policy-based redaction/hashing, signed attestations, and court-ready
    evidence bundles for prompt-injection and data exfiltration incidents.'
  security_requirements:
  - Apply strict redaction and salted hashing to sensitive fields; support allowlisted
    leakage proofs via canary markers without exposing raw PII.
  - Produce cryptographically sealed bundles with chained timestamps and verifiable
    signatures; maintain immutable audit trails and chain-of-custody.
  - Low-overhead instrumentation (middleware/SDK) with no credential harvesting; configurable
    sampling and privacy budgets for production safety.
  acceptance_tests:
  - A simulated prompt-injection that triggers a tool egress attempt is fully recorded
    (prompt hash, tool call, target URL), sealed, and later verified by signature
    and timestamp continuity.
  - Redaction policies replace sensitive fields with salted hashes while preserving
    linkage across events; a verifier can match canary markers without reconstructing
    plaintext.
  - Middleware integration in a sample LangChain app adds less than a 5% latency overhead
    and produces a complete, tamper-evident evidence bundle on demand.
  ready: true
  status: todo
  area_allowlist:
  - tools/forensics/llmchain_forensic_recorder.py
  - tests/test_forensics_008.py
  max_changed_lines: 500
- id: IOT-007
  title: 'MatterMesh Auditor: Thread/Matter/Zigbee Commissioning & Key Hygiene Tester'
  category: iot
  description: Passive-first auditing and safety-aware fuzzing of Matter/Thread/Zigbee
    home/edge networks. Validates commissioning flows, key rotation, nonce/DevAddr
    hygiene, and ACL posture using 802.15.4 captures and lab-safe probes. Extracts
    SBOMs from firmware, correlates CVEs, and emits cryptographically sealed findings.
  security_requirements:
  - Default to passive analysis with SDR/pcap inputs; enable active tests only in
    explicit lab mode with rate limits and device allowlists.
  - Store keys/artifacts encrypted-at-rest; sign reports with timestamped attestations
    and redact device identifiers.
  - Implement protocol-aware safety guards that auto-fall-back to passive sniffing
    on critical frames (e.g., Network Reset, Factory Reset) or high error counters.
  acceptance_tests:
  - Given an 802.15.4 PCAP containing a Matter commissioning using a default SPAKE2+
    passcode, the tool flags weak passcode usage with evidence and remediation.
  - When lab mode fuzzes a Thread device, the tool never exceeds configured frame-per-second
    and stops on encountering specific error/status frames, logging a safety fallback
    event.
  - Upon firmware SBOM extraction from a Zigbee coordinator image, the tool identifies
    hardcoded link keys and maps them to known CVEs with a sealed report.
  ready: true
  status: todo
  area_allowlist:
  - tools/iot/mattermesh_auditor.py
  - tests/test_iot_007.py
  max_changed_lines: 500
- id: HUNT-004
  title: 'BYOVD Hunter: Malicious Driver Abuse & Kernel Tamper Detector'
  category: threat_hunting
  description: "Detects Bring-Your-Own-Vulnerable-Driver (BYOVD) abuse and kernel\
    \ tampering across Windows/Linux using ETW/eBPF telemetry, driver signature/blocklist\
    \ checks, and kernel object integrity baselines. Correlates temporal chains (driver\
    \ load \u2192 handle opens \u2192 protection tamper) and produces signed incident\
    \ bundles."
  security_requirements:
  - Use least-privilege collectors with kernel-safe sampling budgets; fail-closed
    if overhead exceeds configured thresholds.
  - Continuously verify driver/collector integrity via code signing and secure boot
    measurements; seal evidence with timestamps and transparency logs.
  - Exclude sensitive process payloads; collect metadata/hash-level evidence only,
    with role-based access controls on incident bundles.
  acceptance_tests:
  - Loading a known vulnerable driver hash triggers a high-severity alert referencing
    the blocklist entry and kernel version impact, with a causal chain graph.
  - An unsigned driver load attempt is blocked/flagged, and the tool records ETW/eBPF
    events showing failed/signature-mismatch loading semantics.
  - A simulated EDR self-protection bypass (handle to protected process) is detected
    and correlated to prior driver load, generating a sealed incident bundle.
  ready: true
  status: todo
  area_allowlist:
  - tools/threat_hunting/byovd_hunter.py
  - tests/test_hunt_004.py
  max_changed_lines: 500
- id: MOBILE-004
  title: 'ModelGuard Mobile: On-Device ML Model Exfil & Theft Auditor'
  category: mobile
  description: 'Audits Android/iOS apps for on-device ML model risks: unsigned weight
    loading, dynamic code/model injection, embedding/feature exfiltration, and prompt/label
    leakage. Combines static SBOM/model inventory with emulator-based dynamic instrumentation
    (Frida/LLDB) and canary embeddings to detect misuse.'
  security_requirements:
  - Perform on-device data minimization and redact PII; only hash model artifacts
    and endpoints, never store raw user inputs.
  - Sandbox dynamic instrumentation with egress allowlists; block or simulate network
    calls in lab mode to prevent real data exfiltration.
  - Sign and timestamp risk attestations; verify app/SDK signatures and produce reproducible
    SBOMs (SPDX/CycloneDX).
  acceptance_tests:
  - Static analysis of an APK with bundled .pt/.tflite weights produces a model inventory,
    flags missing signature/attestation, and generates an SBOM with hashes.
  - Dynamic run seeds a signed canary embedding and detects an unauthorized egress
    to an unlisted endpoint, raising a critical finding with request metadata.
  - Membership inference risk evaluation on a sample model exceeds threshold and the
    tool blocks release by emitting a signed, policy-gated risk attestation.
  ready: true
  status: todo
  area_allowlist:
  - tools/mobile/modelguard_mobile.py
  - tests/test_mobile_004.py
  max_changed_lines: 500
- id: AI_SECURITY-016
  title: 'EvalGuard: LLM Eval Integrity & Leaderboard Fraud Auditor'
  category: ai_security
  description: Audits LLM evaluation datasets, prompts, harness configs, and run artifacts
    to detect contamination, leakage, collusion, and leaderboard gaming. Verifies
    dataset/model provenance via signed attestations, computes fuzzy/semantic overlap
    with training corpora, detects few-shot/answer leakage, and emits signed, reproducible
    reports that can gate CI/CD promotions.
  security_requirements:
  - Use cryptographic hashing and content-defined chunking to fingerprint datasets
    and prompts; store only salted hashes and embeddings to avoid plaintext leakage.
  - Verify signatures and provenance (Sigstore/in-toto) for datasets, model weights,
    and eval harness; produce append-only, timestamped attestations for all runs.
  - Provide safe redaction and PII filtering for prompts/outputs; enforce sandboxed
    evaluation environments with egress allowlists and tamper-evident logs.
  acceptance_tests:
  - Detects eval contamination when >10% of eval items semantically match the training
    corpus above a configured threshold and blocks leaderboard submission with a signed
    attestation.
  - Identifies prompt templates that leak reference answers or chain-of-thought and
    flags the run as policy-violating with a redacted, reproducible report.
  - Verifies dataset and harness signatures; if any artifact is unsigned or missing
    an attestation, quarantines the run and emits an immutable audit record.
  ready: true
  status: todo
  area_allowlist:
  - tools/ai_security/evalguard.py
  - tests/test_ai_security_evalguard.py
  max_changed_lines: 500
- id: NET-007
  title: 'BrokerShade IDS: MQTT5/AMQP Covert Exfil Hunter'
  category: network
  description: A privacy-preserving IDS for encrypted MQTT5 and AMQP over TLS that
    profiles topic hierarchy entropy, retained message abuse, QoS patterns, user property
    size/frequency, clientID churn, and will-message anomalies. Correlates broker
    fingerprints, SNI/ALPN metadata, and timing features to detect covert data exfiltration
    without decrypting payloads.
  security_requirements:
  - Do not decrypt payloads; analyze only metadata and timing. Minimize PII by hashing
    client IDs and topic strings with a rotating keyed hash.
  - Maintain allowlists for approved brokers and topic namespaces; alert only on deviations
    surpassing statistical baselines to reduce false positives.
  - Produce signed, tamper-evident alert logs and support sealing of flow metadata/PCAP
    headers for downstream forensics.
  acceptance_tests:
  - Flags a covert exfil scenario where a client encodes data in MQTT user properties
    across bursts with anomalous size/timing entropy.
  - Detects retained-message beacons to an unapproved topic namespace and correlates
    with an unknown broker JA3/ALPN fingerprint.
  - Operates without payload visibility and demonstrates <1% false positive rate on
    a clean baseline replay with allowlists applied.
  ready: true
  status: todo
  area_allowlist:
  - tools/network/brokershade_ids.py
  - tests/test_network_brokershade_ids.py
  max_changed_lines: 500
- id: IOT-008
  title: 'OTA Sentinel: IoT TUF/Uptane Update Supply Chain Auditor'
  category: iot
  description: Audits IoT OTA update pipelines and devices for TUF/Uptane compliance,
    signature verification, rollback/fast-forward protections, and transparency log
    inclusion. Seeds signed canary updates, simulates update flows in lab mode, validates
    metadata expiration and root key rotation, and emits policy-gated remediations
    with signed attestations.
  security_requirements:
  - Verify multi-role signatures (root/targets/timestamp/snapshot) and key rotation
    policies; validate transparency log inclusion proofs and external time-stamping.
  - Sandbox update clients in hermetic emulation to observe endpoints, enforce egress
    allowlists, and detect secrets/credential exposure during update.
  - Preserve privacy by redacting device identifiers and storing only salted hashes;
    emit sealed evidence bundles for any integrity failures.
  acceptance_tests:
  - Detects a rollback attack using stale but signed targets metadata, blocks installation,
    and generates remediation steps with a signed report.
  - Fails an update whose artifacts lack transparency log entries or have mismatched
    digests; quarantines the OTA channel and alerts.
  - Runs a canary update simulation in lab mode and validates device policy enforcement
    (pinning, metadata expiration) without impacting production devices.
  ready: true
  status: todo
  area_allowlist:
  - tools/iot/ota_sentinel.py
  - tests/test_iot_ota_sentinel.py
  max_changed_lines: 500
